{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "415e25b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from tensorboard) (1.74.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from tensorboard) (3.8)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from tensorboard) (2.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from tensorboard) (11.1.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from tensorboard) (5.29.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from tensorboard) (72.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: torch in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\82108\\anaconda3\\dfcjsic\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "device = cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard\n",
    "!pip install gymnasium torch numpy pandas matplotlib\n",
    "\n",
    "import os, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device =\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41078313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | ep_reward 12.0 | T=12\n",
      "Epoch 00010 | ep_reward 15.0 | T=15\n",
      "Epoch 00020 | ep_reward 13.0 | T=13\n",
      "Epoch 00030 | ep_reward 28.0 | T=28\n",
      "Epoch 00040 | ep_reward 40.0 | T=40\n",
      "Epoch 00050 | ep_reward 23.0 | T=23\n",
      "Epoch 00060 | ep_reward 32.0 | T=32\n",
      "Epoch 00070 | ep_reward 48.0 | T=48\n",
      "Epoch 00080 | ep_reward 13.0 | T=13\n",
      "Epoch 00090 | ep_reward 19.0 | T=19\n",
      "Epoch 00100 | ep_reward 12.0 | T=12\n",
      "Epoch 00110 | ep_reward 17.0 | T=17\n",
      "Epoch 00120 | ep_reward 22.0 | T=22\n",
      "Epoch 00130 | ep_reward 27.0 | T=27\n",
      "Epoch 00140 | ep_reward 23.0 | T=23\n",
      "Epoch 00150 | ep_reward 27.0 | T=27\n",
      "Epoch 00160 | ep_reward 9.0 | T=9\n",
      "Epoch 00170 | ep_reward 11.0 | T=11\n",
      "Epoch 00180 | ep_reward 10.0 | T=10\n",
      "Epoch 00190 | ep_reward 16.0 | T=16\n",
      "Epoch 00200 | ep_reward 20.0 | T=20\n",
      "Epoch 00210 | ep_reward 58.0 | T=58\n",
      "Epoch 00220 | ep_reward 20.0 | T=20\n",
      "Epoch 00230 | ep_reward 31.0 | T=31\n",
      "Epoch 00240 | ep_reward 14.0 | T=14\n",
      "Epoch 00250 | ep_reward 36.0 | T=36\n",
      "Epoch 00260 | ep_reward 22.0 | T=22\n",
      "Epoch 00270 | ep_reward 19.0 | T=19\n",
      "Epoch 00280 | ep_reward 15.0 | T=15\n",
      "Epoch 00290 | ep_reward 14.0 | T=14\n",
      "Epoch 00300 | ep_reward 31.0 | T=31\n",
      "Epoch 00310 | ep_reward 35.0 | T=35\n",
      "Epoch 00320 | ep_reward 15.0 | T=15\n",
      "Epoch 00330 | ep_reward 20.0 | T=20\n",
      "Epoch 00340 | ep_reward 15.0 | T=15\n",
      "Epoch 00350 | ep_reward 19.0 | T=19\n",
      "Epoch 00360 | ep_reward 21.0 | T=21\n",
      "Epoch 00370 | ep_reward 28.0 | T=28\n",
      "Epoch 00380 | ep_reward 21.0 | T=21\n",
      "Epoch 00390 | ep_reward 14.0 | T=14\n",
      "Epoch 00400 | ep_reward 10.0 | T=10\n",
      "Epoch 00410 | ep_reward 16.0 | T=16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 143\u001b[0m\n\u001b[0;32m    140\u001b[0m actor_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(log_prob \u001b[38;5;241m*\u001b[39m advantage\u001b[38;5;241m.\u001b[39mdetach())\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m    142\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 143\u001b[0m \u001b[43mactor_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(policy\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m    145\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\dfcjsic\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    624\u001b[0m     )\n\u001b[1;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\dfcjsic\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\dfcjsic\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)\n",
    "        self.lstm = nn.LSTM(64, 128, batch_first=True)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # x: (B, T, 2)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        x = self.relu(x)\n",
    "        x = self.sigmoid(self.fc2(x))  # (B, T, 1)\n",
    "        return x, hidden\n",
    "\n",
    "    def select_action(self, state, hidden):\n",
    "        # state: (1, 1, 2)\n",
    "        with torch.no_grad():\n",
    "            prob, hidden = self.forward(state, hidden)  # (1,1,1)\n",
    "            b = Bernoulli(prob)\n",
    "            action = b.sample()  # 0/1\n",
    "        return int(action.item()), hidden\n",
    "\n",
    "\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)\n",
    "        self.lstm = nn.LSTM(64, 256, batch_first=True)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)  # (B,T,1)\n",
    "        return x, hidden\n",
    "\n",
    "\n",
    "def obs_to_partial(obs):\n",
    "    # CartPole obs: [x, x_dot, theta, theta_dot]\n",
    "    # keep only x, theta\n",
    "    return np.array([obs[0], obs[2]], dtype=np.float32)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    policy = PolicyNetwork().to(device)\n",
    "    value = ValueNetwork().to(device)\n",
    "\n",
    "    optim = torch.optim.Adam(policy.parameters(), lr=1e-4)\n",
    "    value_optim = torch.optim.Adam(value.parameters(), lr=3e-4)\n",
    "\n",
    "    gamma = 0.99\n",
    "    writer = SummaryWriter(\"./lstm_logs\")\n",
    "\n",
    "    for epoch in count():\n",
    "        obs, info = env.reset(seed=None)\n",
    "        state = obs_to_partial(obs)\n",
    "        episode_reward = 0.0\n",
    "\n",
    "        # LSTM hidden init\n",
    "        a_hx = torch.zeros((1, 1, 128), device=device)\n",
    "        a_cx = torch.zeros((1, 1, 128), device=device)\n",
    "\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        states = []\n",
    "\n",
    "        for t in range(500):  # CartPole-v1 max is typically 500\n",
    "            states.append(state.copy())\n",
    "\n",
    "            state_t = torch.tensor(state, dtype=torch.float32, device=device).view(1, 1, 2)\n",
    "            action, (a_hx, a_cx) = policy.select_action(state_t, (a_hx, a_cx))\n",
    "            actions.append(action)\n",
    "\n",
    "            next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            next_state = obs_to_partial(next_obs)\n",
    "            episode_reward += float(reward)\n",
    "\n",
    "            rewards.append(float(reward))\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # returns\n",
    "        returns = np.zeros(len(rewards), dtype=np.float32)\n",
    "        R = 0.0\n",
    "        for i in reversed(range(len(rewards))):\n",
    "            R = gamma * R + rewards[i]\n",
    "            returns[i] = R\n",
    "\n",
    "        # normalize returns (stability)\n",
    "        mean, std = returns.mean(), returns.std()\n",
    "        std = std if std > 1e-8 else 1.0\n",
    "        returns = (returns - mean) / std\n",
    "\n",
    "        # tensors\n",
    "        states_tensor = torch.tensor(np.array(states), dtype=torch.float32, device=device).unsqueeze(0)  # (1,T,2)\n",
    "        actions_tensor = torch.tensor(np.array(actions), dtype=torch.float32, device=device).view(-1, 1)  # (T,1)\n",
    "        returns_tensor = torch.tensor(returns, dtype=torch.float32, device=device).view(-1, 1)  # (T,1)\n",
    "\n",
    "        # critic to get baseline\n",
    "        with torch.no_grad():\n",
    "            c_hx = torch.zeros((1, 1, 256), device=device)\n",
    "            c_cx = torch.zeros((1, 1, 256), device=device)\n",
    "            v, _ = value(states_tensor, (c_hx, c_cx))  # (1,T,1)\n",
    "            v = v.squeeze(0)  # (T,1)\n",
    "            advantage = returns_tensor - v  # (T,1)\n",
    "\n",
    "        # actor update (re-run policy on full sequence)\n",
    "        a_hx = torch.zeros((1, 1, 128), device=device)\n",
    "        a_cx = torch.zeros((1, 1, 128), device=device)\n",
    "        prob, _ = policy(states_tensor, (a_hx, a_cx))  # (1,T,1)\n",
    "        prob = prob.squeeze(0)  # (T,1)\n",
    "\n",
    "        b = Bernoulli(prob)\n",
    "        log_prob = b.log_prob(actions_tensor)  # (T,1)\n",
    "\n",
    "        actor_loss = -(log_prob * advantage.detach()).mean()\n",
    "\n",
    "        optim.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(policy.parameters(), 1.0)\n",
    "        optim.step()\n",
    "        writer.add_scalar(\"loss/actor\", actor_loss.item(), epoch)\n",
    "\n",
    "        # critic update\n",
    "        c_hx = torch.zeros((1, 1, 256), device=device)\n",
    "        c_cx = torch.zeros((1, 1, 256), device=device)\n",
    "        v, _ = value(states_tensor, (c_hx, c_cx))\n",
    "        v = v.squeeze(0)\n",
    "        value_loss = F.mse_loss(v, returns_tensor)\n",
    "\n",
    "        value_optim.zero_grad()\n",
    "        value_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(value.parameters(), 1.0)\n",
    "        value_optim.step()\n",
    "        writer.add_scalar(\"loss/value\", value_loss.item(), epoch)\n",
    "\n",
    "        writer.add_scalar(\"episode_reward\", episode_reward, epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch:05d} | ep_reward {episode_reward:.1f} | T={len(rewards)}\")\n",
    "            torch.save(policy.state_dict(), \"lstm-policy.pt\")\n",
    "\n",
    "\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

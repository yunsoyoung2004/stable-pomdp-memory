{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415e25b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard) (2.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard) (11.0.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard) (6.31.0rc2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard) (75.6.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 1.8/4.7 MB 9.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.9/4.7 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 10.2 MB/s  0:00:00\n",
      "Using cached markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading werkzeug-3.1.5-py3-none-any.whl (225 kB)\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, markdown, grpcio, absl-py, tensorboard\n",
      "\n",
      "   ---------------------------------------- 0/6 [werkzeug]\n",
      "   ---------------------------------------- 0/6 [werkzeug]\n",
      "   ------------- -------------------------- 2/6 [markdown]\n",
      "   ------------- -------------------------- 2/6 [markdown]\n",
      "   -------------------- ------------------- 3/6 [grpcio]\n",
      "   -------------------- ------------------- 3/6 [grpcio]\n",
      "   -------------------- ------------------- 3/6 [grpcio]\n",
      "   -------------------------- ------------- 4/6 [absl-py]\n",
      "   --------------------------------- ------ 5/6 [tensorboard]\n",
      "   --------------------------------- ------ 5/6 [tensorboard]\n",
      "   --------------------------------- ------ 5/6 [tensorboard]\n",
      "   --------------------------------- ------ 5/6 [tensorboard]\n",
      "   --------------------------------- ------ 5/6 [tensorboard]\n",
      "   --------------------------------- ------ 5/6 [tensorboard]\n",
      "   --------------------------------- ------ 5/6 [tensorboard]\n",
      "   --------------------------------- ------ 5/6 [tensorboard]\n",
      "   --------------------------------- ------ 5/6 [tensorboard]\n",
      "   --------------------------------- ------ 5/6 [tensorboard]\n",
      "   ---------------------------------------- 6/6 [tensorboard]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 grpcio-1.76.0 markdown-3.10 tensorboard-2.20.0 tensorboard-data-server-0.7.2 werkzeug-3.1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\82108\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: torch in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gymnasium) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gymnasium) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\82108\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\82108\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard\n",
    "!pip install gymnasium torch numpy pandas matplotlib\n",
    "\n",
    "import os, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device =\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41078313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | ep_reward 22.0 | T=22\n",
      "Epoch 00010 | ep_reward 16.0 | T=16\n",
      "Epoch 00020 | ep_reward 50.0 | T=50\n",
      "Epoch 00030 | ep_reward 12.0 | T=12\n",
      "Epoch 00040 | ep_reward 20.0 | T=20\n",
      "Epoch 00050 | ep_reward 18.0 | T=18\n",
      "Epoch 00060 | ep_reward 39.0 | T=39\n",
      "Epoch 00070 | ep_reward 20.0 | T=20\n",
      "Epoch 00080 | ep_reward 13.0 | T=13\n",
      "Epoch 00090 | ep_reward 25.0 | T=25\n",
      "Epoch 00100 | ep_reward 12.0 | T=12\n",
      "Epoch 00110 | ep_reward 32.0 | T=32\n",
      "Epoch 00120 | ep_reward 15.0 | T=15\n",
      "Epoch 00130 | ep_reward 13.0 | T=13\n",
      "Epoch 00140 | ep_reward 49.0 | T=49\n",
      "Epoch 00150 | ep_reward 15.0 | T=15\n",
      "Epoch 00160 | ep_reward 25.0 | T=25\n",
      "Epoch 00170 | ep_reward 28.0 | T=28\n",
      "Epoch 00180 | ep_reward 23.0 | T=23\n",
      "Epoch 00190 | ep_reward 14.0 | T=14\n",
      "Epoch 00200 | ep_reward 38.0 | T=38\n",
      "Epoch 00210 | ep_reward 24.0 | T=24\n",
      "Epoch 00220 | ep_reward 19.0 | T=19\n",
      "Epoch 00230 | ep_reward 21.0 | T=21\n",
      "Epoch 00240 | ep_reward 34.0 | T=34\n",
      "Epoch 00250 | ep_reward 29.0 | T=29\n",
      "Epoch 00260 | ep_reward 21.0 | T=21\n",
      "Epoch 00270 | ep_reward 15.0 | T=15\n",
      "Epoch 00280 | ep_reward 13.0 | T=13\n",
      "Epoch 00290 | ep_reward 14.0 | T=14\n",
      "Epoch 00300 | ep_reward 29.0 | T=29\n",
      "Epoch 00310 | ep_reward 50.0 | T=50\n",
      "Epoch 00320 | ep_reward 36.0 | T=36\n",
      "Epoch 00330 | ep_reward 13.0 | T=13\n",
      "Epoch 00340 | ep_reward 8.0 | T=8\n",
      "Epoch 00350 | ep_reward 14.0 | T=14\n",
      "Epoch 00360 | ep_reward 35.0 | T=35\n",
      "Epoch 00370 | ep_reward 12.0 | T=12\n",
      "Epoch 00380 | ep_reward 18.0 | T=18\n",
      "Epoch 00390 | ep_reward 30.0 | T=30\n",
      "Epoch 00400 | ep_reward 18.0 | T=18\n",
      "Epoch 00410 | ep_reward 27.0 | T=27\n",
      "Epoch 00420 | ep_reward 12.0 | T=12\n",
      "Epoch 00430 | ep_reward 21.0 | T=21\n",
      "Epoch 00440 | ep_reward 15.0 | T=15\n",
      "Epoch 00450 | ep_reward 11.0 | T=11\n",
      "Epoch 00460 | ep_reward 21.0 | T=21\n",
      "Epoch 00470 | ep_reward 16.0 | T=16\n",
      "Epoch 00480 | ep_reward 18.0 | T=18\n",
      "Epoch 00490 | ep_reward 12.0 | T=12\n",
      "Epoch 00500 | ep_reward 30.0 | T=30\n",
      "Epoch 00510 | ep_reward 21.0 | T=21\n",
      "Epoch 00520 | ep_reward 17.0 | T=17\n",
      "Epoch 00530 | ep_reward 13.0 | T=13\n",
      "Epoch 00540 | ep_reward 19.0 | T=19\n",
      "Epoch 00550 | ep_reward 24.0 | T=24\n",
      "Epoch 00560 | ep_reward 35.0 | T=35\n",
      "Epoch 00570 | ep_reward 16.0 | T=16\n",
      "Epoch 00580 | ep_reward 10.0 | T=10\n",
      "Epoch 00590 | ep_reward 19.0 | T=19\n",
      "Epoch 00600 | ep_reward 27.0 | T=27\n",
      "Epoch 00610 | ep_reward 24.0 | T=24\n",
      "Epoch 00620 | ep_reward 28.0 | T=28\n",
      "Epoch 00630 | ep_reward 9.0 | T=9\n",
      "Epoch 00640 | ep_reward 15.0 | T=15\n",
      "Epoch 00650 | ep_reward 24.0 | T=24\n",
      "Epoch 00660 | ep_reward 22.0 | T=22\n",
      "Epoch 00670 | ep_reward 12.0 | T=12\n",
      "Epoch 00680 | ep_reward 22.0 | T=22\n",
      "Epoch 00690 | ep_reward 18.0 | T=18\n",
      "Epoch 00700 | ep_reward 32.0 | T=32\n",
      "Epoch 00710 | ep_reward 16.0 | T=16\n",
      "Epoch 00720 | ep_reward 19.0 | T=19\n",
      "Epoch 00730 | ep_reward 37.0 | T=37\n",
      "Epoch 00740 | ep_reward 17.0 | T=17\n",
      "Epoch 00750 | ep_reward 18.0 | T=18\n",
      "Epoch 00760 | ep_reward 25.0 | T=25\n",
      "Epoch 00770 | ep_reward 11.0 | T=11\n",
      "Epoch 00780 | ep_reward 16.0 | T=16\n",
      "Epoch 00790 | ep_reward 13.0 | T=13\n",
      "Epoch 00800 | ep_reward 41.0 | T=41\n",
      "Epoch 00810 | ep_reward 18.0 | T=18\n",
      "Epoch 00820 | ep_reward 19.0 | T=19\n",
      "Epoch 00830 | ep_reward 21.0 | T=21\n",
      "Epoch 00840 | ep_reward 16.0 | T=16\n",
      "Epoch 00850 | ep_reward 22.0 | T=22\n",
      "Epoch 00860 | ep_reward 14.0 | T=14\n",
      "Epoch 00870 | ep_reward 38.0 | T=38\n",
      "Epoch 00880 | ep_reward 46.0 | T=46\n",
      "Epoch 00890 | ep_reward 32.0 | T=32\n",
      "Epoch 00900 | ep_reward 47.0 | T=47\n",
      "Epoch 00910 | ep_reward 18.0 | T=18\n",
      "Epoch 00920 | ep_reward 16.0 | T=16\n",
      "Epoch 00930 | ep_reward 22.0 | T=22\n",
      "Epoch 00940 | ep_reward 25.0 | T=25\n",
      "Epoch 00950 | ep_reward 28.0 | T=28\n",
      "Epoch 00960 | ep_reward 10.0 | T=10\n",
      "Epoch 00970 | ep_reward 68.0 | T=68\n",
      "Epoch 00980 | ep_reward 14.0 | T=14\n",
      "Epoch 00990 | ep_reward 17.0 | T=17\n",
      "Epoch 01000 | ep_reward 13.0 | T=13\n",
      "Epoch 01010 | ep_reward 69.0 | T=69\n",
      "Epoch 01020 | ep_reward 50.0 | T=50\n",
      "Epoch 01030 | ep_reward 19.0 | T=19\n",
      "Epoch 01040 | ep_reward 21.0 | T=21\n",
      "Epoch 01050 | ep_reward 16.0 | T=16\n",
      "Epoch 01060 | ep_reward 13.0 | T=13\n",
      "Epoch 01070 | ep_reward 11.0 | T=11\n",
      "Epoch 01080 | ep_reward 12.0 | T=12\n",
      "Epoch 01090 | ep_reward 17.0 | T=17\n",
      "Epoch 01100 | ep_reward 10.0 | T=10\n",
      "Epoch 01110 | ep_reward 18.0 | T=18\n",
      "Epoch 01120 | ep_reward 36.0 | T=36\n",
      "Epoch 01130 | ep_reward 44.0 | T=44\n",
      "Epoch 01140 | ep_reward 32.0 | T=32\n",
      "Epoch 01150 | ep_reward 13.0 | T=13\n",
      "Epoch 01160 | ep_reward 10.0 | T=10\n",
      "Epoch 01170 | ep_reward 11.0 | T=11\n",
      "Epoch 01180 | ep_reward 10.0 | T=10\n",
      "Epoch 01190 | ep_reward 12.0 | T=12\n",
      "Epoch 01200 | ep_reward 34.0 | T=34\n",
      "Epoch 01210 | ep_reward 19.0 | T=19\n",
      "Epoch 01220 | ep_reward 29.0 | T=29\n",
      "Epoch 01230 | ep_reward 20.0 | T=20\n",
      "Epoch 01240 | ep_reward 31.0 | T=31\n",
      "Epoch 01250 | ep_reward 15.0 | T=15\n",
      "Epoch 01260 | ep_reward 29.0 | T=29\n",
      "Epoch 01270 | ep_reward 44.0 | T=44\n",
      "Epoch 01280 | ep_reward 27.0 | T=27\n",
      "Epoch 01290 | ep_reward 26.0 | T=26\n",
      "Epoch 01300 | ep_reward 13.0 | T=13\n",
      "Epoch 01310 | ep_reward 26.0 | T=26\n",
      "Epoch 01320 | ep_reward 24.0 | T=24\n",
      "Epoch 01330 | ep_reward 19.0 | T=19\n",
      "Epoch 01340 | ep_reward 22.0 | T=22\n",
      "Epoch 01350 | ep_reward 22.0 | T=22\n",
      "Epoch 01360 | ep_reward 41.0 | T=41\n",
      "Epoch 01370 | ep_reward 12.0 | T=12\n",
      "Epoch 01380 | ep_reward 28.0 | T=28\n",
      "Epoch 01390 | ep_reward 19.0 | T=19\n",
      "Epoch 01400 | ep_reward 16.0 | T=16\n",
      "Epoch 01410 | ep_reward 15.0 | T=15\n",
      "Epoch 01420 | ep_reward 17.0 | T=17\n",
      "Epoch 01430 | ep_reward 15.0 | T=15\n",
      "Epoch 01440 | ep_reward 14.0 | T=14\n",
      "Epoch 01450 | ep_reward 23.0 | T=23\n",
      "Epoch 01460 | ep_reward 12.0 | T=12\n",
      "Epoch 01470 | ep_reward 39.0 | T=39\n",
      "Epoch 01480 | ep_reward 15.0 | T=15\n",
      "Epoch 01490 | ep_reward 13.0 | T=13\n",
      "Epoch 01500 | ep_reward 28.0 | T=28\n",
      "Epoch 01510 | ep_reward 20.0 | T=20\n",
      "Epoch 01520 | ep_reward 23.0 | T=23\n",
      "Epoch 01530 | ep_reward 18.0 | T=18\n",
      "Epoch 01540 | ep_reward 14.0 | T=14\n",
      "Epoch 01550 | ep_reward 12.0 | T=12\n",
      "Epoch 01560 | ep_reward 21.0 | T=21\n",
      "Epoch 01570 | ep_reward 17.0 | T=17\n",
      "Epoch 01580 | ep_reward 24.0 | T=24\n",
      "Epoch 01590 | ep_reward 18.0 | T=18\n",
      "Epoch 01600 | ep_reward 30.0 | T=30\n",
      "Epoch 01610 | ep_reward 38.0 | T=38\n",
      "Epoch 01620 | ep_reward 67.0 | T=67\n",
      "Epoch 01630 | ep_reward 43.0 | T=43\n",
      "Epoch 01640 | ep_reward 14.0 | T=14\n",
      "Epoch 01650 | ep_reward 49.0 | T=49\n",
      "Epoch 01660 | ep_reward 23.0 | T=23\n",
      "Epoch 01670 | ep_reward 13.0 | T=13\n",
      "Epoch 01680 | ep_reward 32.0 | T=32\n",
      "Epoch 01690 | ep_reward 19.0 | T=19\n",
      "Epoch 01700 | ep_reward 21.0 | T=21\n",
      "Epoch 01710 | ep_reward 53.0 | T=53\n",
      "Epoch 01720 | ep_reward 22.0 | T=22\n",
      "Epoch 01730 | ep_reward 20.0 | T=20\n",
      "Epoch 01740 | ep_reward 23.0 | T=23\n",
      "Epoch 01750 | ep_reward 33.0 | T=33\n",
      "Epoch 01760 | ep_reward 47.0 | T=47\n",
      "Epoch 01770 | ep_reward 11.0 | T=11\n",
      "Epoch 01780 | ep_reward 25.0 | T=25\n",
      "Epoch 01790 | ep_reward 12.0 | T=12\n",
      "Epoch 01800 | ep_reward 10.0 | T=10\n",
      "Epoch 01810 | ep_reward 30.0 | T=30\n",
      "Epoch 01820 | ep_reward 15.0 | T=15\n",
      "Epoch 01830 | ep_reward 11.0 | T=11\n",
      "Epoch 01840 | ep_reward 19.0 | T=19\n",
      "Epoch 01850 | ep_reward 16.0 | T=16\n",
      "Epoch 01860 | ep_reward 44.0 | T=44\n",
      "Epoch 01870 | ep_reward 18.0 | T=18\n",
      "Epoch 01880 | ep_reward 64.0 | T=64\n",
      "Epoch 01890 | ep_reward 13.0 | T=13\n",
      "Epoch 01900 | ep_reward 13.0 | T=13\n",
      "Epoch 01910 | ep_reward 21.0 | T=21\n",
      "Epoch 01920 | ep_reward 47.0 | T=47\n",
      "Epoch 01930 | ep_reward 17.0 | T=17\n",
      "Epoch 01940 | ep_reward 18.0 | T=18\n",
      "Epoch 01950 | ep_reward 38.0 | T=38\n",
      "Epoch 01960 | ep_reward 10.0 | T=10\n",
      "Epoch 01970 | ep_reward 13.0 | T=13\n",
      "Epoch 01980 | ep_reward 39.0 | T=39\n",
      "Epoch 01990 | ep_reward 28.0 | T=28\n",
      "Epoch 02000 | ep_reward 17.0 | T=17\n",
      "Epoch 02010 | ep_reward 38.0 | T=38\n",
      "Epoch 02020 | ep_reward 39.0 | T=39\n",
      "Epoch 02030 | ep_reward 59.0 | T=59\n",
      "Epoch 02040 | ep_reward 21.0 | T=21\n",
      "Epoch 02050 | ep_reward 13.0 | T=13\n",
      "Epoch 02060 | ep_reward 38.0 | T=38\n",
      "Epoch 02070 | ep_reward 9.0 | T=9\n",
      "Epoch 02080 | ep_reward 12.0 | T=12\n",
      "Epoch 02090 | ep_reward 15.0 | T=15\n",
      "Epoch 02100 | ep_reward 16.0 | T=16\n",
      "Epoch 02110 | ep_reward 36.0 | T=36\n",
      "Epoch 02120 | ep_reward 34.0 | T=34\n",
      "Epoch 02130 | ep_reward 18.0 | T=18\n",
      "Epoch 02140 | ep_reward 42.0 | T=42\n",
      "Epoch 02150 | ep_reward 11.0 | T=11\n",
      "Epoch 02160 | ep_reward 20.0 | T=20\n",
      "Epoch 02170 | ep_reward 15.0 | T=15\n",
      "Epoch 02180 | ep_reward 13.0 | T=13\n",
      "Epoch 02190 | ep_reward 27.0 | T=27\n",
      "Epoch 02200 | ep_reward 24.0 | T=24\n",
      "Epoch 02210 | ep_reward 19.0 | T=19\n",
      "Epoch 02220 | ep_reward 48.0 | T=48\n",
      "Epoch 02230 | ep_reward 38.0 | T=38\n",
      "Epoch 02240 | ep_reward 36.0 | T=36\n",
      "Epoch 02250 | ep_reward 37.0 | T=37\n",
      "Epoch 02260 | ep_reward 22.0 | T=22\n",
      "Epoch 02270 | ep_reward 35.0 | T=35\n",
      "Epoch 02280 | ep_reward 62.0 | T=62\n",
      "Epoch 02290 | ep_reward 29.0 | T=29\n",
      "Epoch 02300 | ep_reward 54.0 | T=54\n",
      "Epoch 02310 | ep_reward 15.0 | T=15\n",
      "Epoch 02320 | ep_reward 25.0 | T=25\n",
      "Epoch 02330 | ep_reward 109.0 | T=109\n",
      "Epoch 02340 | ep_reward 10.0 | T=10\n",
      "Epoch 02350 | ep_reward 16.0 | T=16\n",
      "Epoch 02360 | ep_reward 18.0 | T=18\n",
      "Epoch 02370 | ep_reward 18.0 | T=18\n",
      "Epoch 02380 | ep_reward 56.0 | T=56\n",
      "Epoch 02390 | ep_reward 38.0 | T=38\n",
      "Epoch 02400 | ep_reward 27.0 | T=27\n",
      "Epoch 02410 | ep_reward 31.0 | T=31\n",
      "Epoch 02420 | ep_reward 63.0 | T=63\n",
      "Epoch 02430 | ep_reward 41.0 | T=41\n",
      "Epoch 02440 | ep_reward 45.0 | T=45\n",
      "Epoch 02450 | ep_reward 23.0 | T=23\n",
      "Epoch 02460 | ep_reward 15.0 | T=15\n",
      "Epoch 02470 | ep_reward 35.0 | T=35\n",
      "Epoch 02480 | ep_reward 64.0 | T=64\n",
      "Epoch 02490 | ep_reward 37.0 | T=37\n",
      "Epoch 02500 | ep_reward 48.0 | T=48\n",
      "Epoch 02510 | ep_reward 29.0 | T=29\n",
      "Epoch 02520 | ep_reward 38.0 | T=38\n",
      "Epoch 02530 | ep_reward 52.0 | T=52\n",
      "Epoch 02540 | ep_reward 30.0 | T=30\n",
      "Epoch 02550 | ep_reward 30.0 | T=30\n",
      "Epoch 02560 | ep_reward 45.0 | T=45\n",
      "Epoch 02570 | ep_reward 50.0 | T=50\n",
      "Epoch 02580 | ep_reward 92.0 | T=92\n",
      "Epoch 02590 | ep_reward 62.0 | T=62\n",
      "Epoch 02600 | ep_reward 15.0 | T=15\n",
      "Epoch 02610 | ep_reward 89.0 | T=89\n",
      "Epoch 02620 | ep_reward 22.0 | T=22\n",
      "Epoch 02630 | ep_reward 52.0 | T=52\n",
      "Epoch 02640 | ep_reward 31.0 | T=31\n",
      "Epoch 02650 | ep_reward 42.0 | T=42\n",
      "Epoch 02660 | ep_reward 23.0 | T=23\n",
      "Epoch 02670 | ep_reward 55.0 | T=55\n",
      "Epoch 02680 | ep_reward 29.0 | T=29\n",
      "Epoch 02690 | ep_reward 56.0 | T=56\n",
      "Epoch 02700 | ep_reward 18.0 | T=18\n",
      "Epoch 02710 | ep_reward 34.0 | T=34\n",
      "Epoch 02720 | ep_reward 43.0 | T=43\n",
      "Epoch 02730 | ep_reward 63.0 | T=63\n",
      "Epoch 02740 | ep_reward 70.0 | T=70\n",
      "Epoch 02750 | ep_reward 36.0 | T=36\n",
      "Epoch 02760 | ep_reward 41.0 | T=41\n",
      "Epoch 02770 | ep_reward 137.0 | T=137\n",
      "Epoch 02780 | ep_reward 70.0 | T=70\n",
      "Epoch 02790 | ep_reward 37.0 | T=37\n",
      "Epoch 02800 | ep_reward 27.0 | T=27\n",
      "Epoch 02810 | ep_reward 38.0 | T=38\n",
      "Epoch 02820 | ep_reward 65.0 | T=65\n",
      "Epoch 02830 | ep_reward 53.0 | T=53\n",
      "Epoch 02840 | ep_reward 14.0 | T=14\n",
      "Epoch 02850 | ep_reward 29.0 | T=29\n",
      "Epoch 02860 | ep_reward 64.0 | T=64\n",
      "Epoch 02870 | ep_reward 19.0 | T=19\n",
      "Epoch 02880 | ep_reward 37.0 | T=37\n",
      "Epoch 02890 | ep_reward 30.0 | T=30\n",
      "Epoch 02900 | ep_reward 36.0 | T=36\n",
      "Epoch 02910 | ep_reward 37.0 | T=37\n",
      "Epoch 02920 | ep_reward 17.0 | T=17\n",
      "Epoch 02930 | ep_reward 41.0 | T=41\n",
      "Epoch 02940 | ep_reward 20.0 | T=20\n",
      "Epoch 02950 | ep_reward 61.0 | T=61\n",
      "Epoch 02960 | ep_reward 28.0 | T=28\n",
      "Epoch 02970 | ep_reward 52.0 | T=52\n",
      "Epoch 02980 | ep_reward 41.0 | T=41\n",
      "Epoch 02990 | ep_reward 59.0 | T=59\n",
      "Epoch 03000 | ep_reward 37.0 | T=37\n",
      "Epoch 03010 | ep_reward 56.0 | T=56\n",
      "Epoch 03020 | ep_reward 61.0 | T=61\n",
      "Epoch 03030 | ep_reward 37.0 | T=37\n",
      "Epoch 03040 | ep_reward 61.0 | T=61\n",
      "Epoch 03050 | ep_reward 48.0 | T=48\n",
      "Epoch 03060 | ep_reward 43.0 | T=43\n",
      "Epoch 03070 | ep_reward 40.0 | T=40\n",
      "Epoch 03080 | ep_reward 47.0 | T=47\n",
      "Epoch 03090 | ep_reward 33.0 | T=33\n",
      "Epoch 03100 | ep_reward 43.0 | T=43\n",
      "Epoch 03110 | ep_reward 164.0 | T=164\n",
      "Epoch 03120 | ep_reward 62.0 | T=62\n",
      "Epoch 03130 | ep_reward 95.0 | T=95\n",
      "Epoch 03140 | ep_reward 45.0 | T=45\n",
      "Epoch 03150 | ep_reward 35.0 | T=35\n",
      "Epoch 03160 | ep_reward 20.0 | T=20\n",
      "Epoch 03170 | ep_reward 46.0 | T=46\n",
      "Epoch 03180 | ep_reward 16.0 | T=16\n",
      "Epoch 03190 | ep_reward 49.0 | T=49\n",
      "Epoch 03200 | ep_reward 47.0 | T=47\n",
      "Epoch 03210 | ep_reward 64.0 | T=64\n",
      "Epoch 03220 | ep_reward 80.0 | T=80\n",
      "Epoch 03230 | ep_reward 49.0 | T=49\n",
      "Epoch 03240 | ep_reward 100.0 | T=100\n",
      "Epoch 03250 | ep_reward 87.0 | T=87\n",
      "Epoch 03260 | ep_reward 25.0 | T=25\n",
      "Epoch 03270 | ep_reward 45.0 | T=45\n",
      "Epoch 03280 | ep_reward 49.0 | T=49\n",
      "Epoch 03290 | ep_reward 38.0 | T=38\n",
      "Epoch 03300 | ep_reward 54.0 | T=54\n",
      "Epoch 03310 | ep_reward 40.0 | T=40\n",
      "Epoch 03320 | ep_reward 70.0 | T=70\n",
      "Epoch 03330 | ep_reward 65.0 | T=65\n",
      "Epoch 03340 | ep_reward 76.0 | T=76\n",
      "Epoch 03350 | ep_reward 31.0 | T=31\n",
      "Epoch 03360 | ep_reward 27.0 | T=27\n",
      "Epoch 03370 | ep_reward 26.0 | T=26\n",
      "Epoch 03380 | ep_reward 52.0 | T=52\n",
      "Epoch 03390 | ep_reward 14.0 | T=14\n",
      "Epoch 03400 | ep_reward 63.0 | T=63\n",
      "Epoch 03410 | ep_reward 35.0 | T=35\n",
      "Epoch 03420 | ep_reward 22.0 | T=22\n",
      "Epoch 03430 | ep_reward 26.0 | T=26\n",
      "Epoch 03440 | ep_reward 47.0 | T=47\n",
      "Epoch 03450 | ep_reward 23.0 | T=23\n",
      "Epoch 03460 | ep_reward 48.0 | T=48\n",
      "Epoch 03470 | ep_reward 57.0 | T=57\n",
      "Epoch 03480 | ep_reward 9.0 | T=9\n",
      "Epoch 03490 | ep_reward 67.0 | T=67\n",
      "Epoch 03500 | ep_reward 30.0 | T=30\n",
      "Epoch 03510 | ep_reward 50.0 | T=50\n",
      "Epoch 03520 | ep_reward 19.0 | T=19\n",
      "Epoch 03530 | ep_reward 30.0 | T=30\n",
      "Epoch 03540 | ep_reward 13.0 | T=13\n",
      "Epoch 03550 | ep_reward 12.0 | T=12\n",
      "Epoch 03560 | ep_reward 27.0 | T=27\n",
      "Epoch 03570 | ep_reward 35.0 | T=35\n",
      "Epoch 03580 | ep_reward 51.0 | T=51\n",
      "Epoch 03590 | ep_reward 26.0 | T=26\n",
      "Epoch 03600 | ep_reward 43.0 | T=43\n",
      "Epoch 03610 | ep_reward 22.0 | T=22\n",
      "Epoch 03620 | ep_reward 15.0 | T=15\n",
      "Epoch 03630 | ep_reward 21.0 | T=21\n",
      "Epoch 03640 | ep_reward 66.0 | T=66\n",
      "Epoch 03650 | ep_reward 12.0 | T=12\n",
      "Epoch 03660 | ep_reward 39.0 | T=39\n",
      "Epoch 03670 | ep_reward 87.0 | T=87\n",
      "Epoch 03680 | ep_reward 49.0 | T=49\n",
      "Epoch 03690 | ep_reward 59.0 | T=59\n",
      "Epoch 03700 | ep_reward 65.0 | T=65\n",
      "Epoch 03710 | ep_reward 25.0 | T=25\n",
      "Epoch 03720 | ep_reward 55.0 | T=55\n",
      "Epoch 03730 | ep_reward 163.0 | T=163\n",
      "Epoch 03740 | ep_reward 16.0 | T=16\n",
      "Epoch 03750 | ep_reward 109.0 | T=109\n",
      "Epoch 03760 | ep_reward 33.0 | T=33\n",
      "Epoch 03770 | ep_reward 33.0 | T=33\n",
      "Epoch 03780 | ep_reward 48.0 | T=48\n",
      "Epoch 03790 | ep_reward 90.0 | T=90\n",
      "Epoch 03800 | ep_reward 12.0 | T=12\n",
      "Epoch 03810 | ep_reward 76.0 | T=76\n",
      "Epoch 03820 | ep_reward 81.0 | T=81\n",
      "Epoch 03830 | ep_reward 45.0 | T=45\n",
      "Epoch 03840 | ep_reward 43.0 | T=43\n",
      "Epoch 03850 | ep_reward 35.0 | T=35\n",
      "Epoch 03860 | ep_reward 59.0 | T=59\n",
      "Epoch 03870 | ep_reward 14.0 | T=14\n",
      "Epoch 03880 | ep_reward 23.0 | T=23\n",
      "Epoch 03890 | ep_reward 15.0 | T=15\n",
      "Epoch 03900 | ep_reward 59.0 | T=59\n",
      "Epoch 03910 | ep_reward 63.0 | T=63\n",
      "Epoch 03920 | ep_reward 18.0 | T=18\n",
      "Epoch 03930 | ep_reward 15.0 | T=15\n",
      "Epoch 03940 | ep_reward 67.0 | T=67\n",
      "Epoch 03950 | ep_reward 59.0 | T=59\n",
      "Epoch 03960 | ep_reward 80.0 | T=80\n",
      "Epoch 03970 | ep_reward 34.0 | T=34\n",
      "Epoch 03980 | ep_reward 108.0 | T=108\n",
      "Epoch 03990 | ep_reward 77.0 | T=77\n",
      "Epoch 04000 | ep_reward 36.0 | T=36\n",
      "Epoch 04010 | ep_reward 27.0 | T=27\n",
      "Epoch 04020 | ep_reward 71.0 | T=71\n",
      "Epoch 04030 | ep_reward 96.0 | T=96\n",
      "Epoch 04040 | ep_reward 47.0 | T=47\n",
      "Epoch 04050 | ep_reward 29.0 | T=29\n",
      "Epoch 04060 | ep_reward 102.0 | T=102\n",
      "Epoch 04070 | ep_reward 62.0 | T=62\n",
      "Epoch 04080 | ep_reward 67.0 | T=67\n",
      "Epoch 04090 | ep_reward 12.0 | T=12\n",
      "Epoch 04100 | ep_reward 85.0 | T=85\n",
      "Epoch 04110 | ep_reward 59.0 | T=59\n",
      "Epoch 04120 | ep_reward 66.0 | T=66\n",
      "Epoch 04130 | ep_reward 25.0 | T=25\n",
      "Epoch 04140 | ep_reward 23.0 | T=23\n",
      "Epoch 04150 | ep_reward 119.0 | T=119\n",
      "Epoch 04160 | ep_reward 126.0 | T=126\n",
      "Epoch 04170 | ep_reward 46.0 | T=46\n",
      "Epoch 04180 | ep_reward 47.0 | T=47\n",
      "Epoch 04190 | ep_reward 77.0 | T=77\n",
      "Epoch 04200 | ep_reward 57.0 | T=57\n",
      "Epoch 04210 | ep_reward 27.0 | T=27\n",
      "Epoch 04220 | ep_reward 92.0 | T=92\n",
      "Epoch 04230 | ep_reward 101.0 | T=101\n",
      "Epoch 04240 | ep_reward 89.0 | T=89\n",
      "Epoch 04250 | ep_reward 68.0 | T=68\n",
      "Epoch 04260 | ep_reward 108.0 | T=108\n",
      "Epoch 04270 | ep_reward 69.0 | T=69\n",
      "Epoch 04280 | ep_reward 22.0 | T=22\n",
      "Epoch 04290 | ep_reward 54.0 | T=54\n",
      "Epoch 04300 | ep_reward 147.0 | T=147\n",
      "Epoch 04310 | ep_reward 92.0 | T=92\n",
      "Epoch 04320 | ep_reward 19.0 | T=19\n",
      "Epoch 04330 | ep_reward 49.0 | T=49\n",
      "Epoch 04340 | ep_reward 15.0 | T=15\n",
      "Epoch 04350 | ep_reward 81.0 | T=81\n",
      "Epoch 04360 | ep_reward 67.0 | T=67\n",
      "Epoch 04370 | ep_reward 65.0 | T=65\n",
      "Epoch 04380 | ep_reward 71.0 | T=71\n",
      "Epoch 04390 | ep_reward 57.0 | T=57\n",
      "Epoch 04400 | ep_reward 139.0 | T=139\n",
      "Epoch 04410 | ep_reward 53.0 | T=53\n",
      "Epoch 04420 | ep_reward 107.0 | T=107\n",
      "Epoch 04430 | ep_reward 54.0 | T=54\n",
      "Epoch 04440 | ep_reward 143.0 | T=143\n",
      "Epoch 04450 | ep_reward 160.0 | T=160\n",
      "Epoch 04460 | ep_reward 93.0 | T=93\n",
      "Epoch 04470 | ep_reward 130.0 | T=130\n",
      "Epoch 04480 | ep_reward 13.0 | T=13\n",
      "Epoch 04490 | ep_reward 74.0 | T=74\n",
      "Epoch 04500 | ep_reward 11.0 | T=11\n",
      "Epoch 04510 | ep_reward 50.0 | T=50\n",
      "Epoch 04520 | ep_reward 24.0 | T=24\n",
      "Epoch 04530 | ep_reward 44.0 | T=44\n",
      "Epoch 04540 | ep_reward 159.0 | T=159\n",
      "Epoch 04550 | ep_reward 122.0 | T=122\n",
      "Epoch 04560 | ep_reward 11.0 | T=11\n",
      "Epoch 04570 | ep_reward 152.0 | T=152\n",
      "Epoch 04580 | ep_reward 65.0 | T=65\n",
      "Epoch 04590 | ep_reward 20.0 | T=20\n",
      "Epoch 04600 | ep_reward 96.0 | T=96\n",
      "Epoch 04610 | ep_reward 89.0 | T=89\n",
      "Epoch 04620 | ep_reward 147.0 | T=147\n",
      "Epoch 04630 | ep_reward 112.0 | T=112\n",
      "Epoch 04640 | ep_reward 27.0 | T=27\n",
      "Epoch 04650 | ep_reward 24.0 | T=24\n",
      "Epoch 04660 | ep_reward 13.0 | T=13\n",
      "Epoch 04670 | ep_reward 57.0 | T=57\n",
      "Epoch 04680 | ep_reward 29.0 | T=29\n",
      "Epoch 04690 | ep_reward 84.0 | T=84\n",
      "Epoch 04700 | ep_reward 74.0 | T=74\n",
      "Epoch 04710 | ep_reward 11.0 | T=11\n",
      "Epoch 04720 | ep_reward 85.0 | T=85\n",
      "Epoch 04730 | ep_reward 100.0 | T=100\n",
      "Epoch 04740 | ep_reward 125.0 | T=125\n",
      "Epoch 04750 | ep_reward 25.0 | T=25\n",
      "Epoch 04760 | ep_reward 103.0 | T=103\n",
      "Epoch 04770 | ep_reward 68.0 | T=68\n",
      "Epoch 04780 | ep_reward 37.0 | T=37\n",
      "Epoch 04790 | ep_reward 47.0 | T=47\n",
      "Epoch 04800 | ep_reward 164.0 | T=164\n",
      "Epoch 04810 | ep_reward 35.0 | T=35\n",
      "Epoch 04820 | ep_reward 110.0 | T=110\n",
      "Epoch 04830 | ep_reward 27.0 | T=27\n",
      "Epoch 04840 | ep_reward 159.0 | T=159\n",
      "Epoch 04850 | ep_reward 93.0 | T=93\n",
      "Epoch 04860 | ep_reward 102.0 | T=102\n",
      "Epoch 04870 | ep_reward 57.0 | T=57\n",
      "Epoch 04880 | ep_reward 75.0 | T=75\n",
      "Epoch 04890 | ep_reward 80.0 | T=80\n",
      "Epoch 04900 | ep_reward 103.0 | T=103\n",
      "Epoch 04910 | ep_reward 71.0 | T=71\n",
      "Epoch 04920 | ep_reward 126.0 | T=126\n",
      "Epoch 04930 | ep_reward 14.0 | T=14\n",
      "Epoch 04940 | ep_reward 56.0 | T=56\n",
      "Epoch 04950 | ep_reward 235.0 | T=235\n",
      "Epoch 04960 | ep_reward 24.0 | T=24\n",
      "Epoch 04970 | ep_reward 85.0 | T=85\n",
      "Epoch 04980 | ep_reward 98.0 | T=98\n",
      "Epoch 04990 | ep_reward 11.0 | T=11\n",
      "Epoch 05000 | ep_reward 161.0 | T=161\n",
      "Epoch 05010 | ep_reward 105.0 | T=105\n",
      "Epoch 05020 | ep_reward 11.0 | T=11\n",
      "Epoch 05030 | ep_reward 43.0 | T=43\n",
      "Epoch 05040 | ep_reward 26.0 | T=26\n",
      "Epoch 05050 | ep_reward 221.0 | T=221\n",
      "Epoch 05060 | ep_reward 11.0 | T=11\n",
      "Epoch 05070 | ep_reward 15.0 | T=15\n",
      "Epoch 05080 | ep_reward 70.0 | T=70\n",
      "Epoch 05090 | ep_reward 91.0 | T=91\n",
      "Epoch 05100 | ep_reward 52.0 | T=52\n",
      "Epoch 05110 | ep_reward 110.0 | T=110\n",
      "Epoch 05120 | ep_reward 191.0 | T=191\n",
      "Epoch 05130 | ep_reward 92.0 | T=92\n",
      "Epoch 05140 | ep_reward 80.0 | T=80\n",
      "Epoch 05150 | ep_reward 97.0 | T=97\n",
      "Epoch 05160 | ep_reward 53.0 | T=53\n",
      "Epoch 05170 | ep_reward 10.0 | T=10\n",
      "Epoch 05180 | ep_reward 175.0 | T=175\n",
      "Epoch 05190 | ep_reward 40.0 | T=40\n",
      "Epoch 05200 | ep_reward 128.0 | T=128\n",
      "Epoch 05210 | ep_reward 214.0 | T=214\n",
      "Epoch 05220 | ep_reward 120.0 | T=120\n",
      "Epoch 05230 | ep_reward 26.0 | T=26\n",
      "Epoch 05240 | ep_reward 22.0 | T=22\n",
      "Epoch 05250 | ep_reward 220.0 | T=220\n",
      "Epoch 05260 | ep_reward 163.0 | T=163\n",
      "Epoch 05270 | ep_reward 13.0 | T=13\n",
      "Epoch 05280 | ep_reward 12.0 | T=12\n",
      "Epoch 05290 | ep_reward 26.0 | T=26\n",
      "Epoch 05300 | ep_reward 217.0 | T=217\n",
      "Epoch 05310 | ep_reward 111.0 | T=111\n",
      "Epoch 05320 | ep_reward 190.0 | T=190\n",
      "Epoch 05330 | ep_reward 73.0 | T=73\n",
      "Epoch 05340 | ep_reward 224.0 | T=224\n",
      "Epoch 05350 | ep_reward 135.0 | T=135\n",
      "Epoch 05360 | ep_reward 127.0 | T=127\n",
      "Epoch 05370 | ep_reward 83.0 | T=83\n",
      "Epoch 05380 | ep_reward 114.0 | T=114\n",
      "Epoch 05390 | ep_reward 235.0 | T=235\n",
      "Epoch 05400 | ep_reward 24.0 | T=24\n",
      "Epoch 05410 | ep_reward 150.0 | T=150\n",
      "Epoch 05420 | ep_reward 171.0 | T=171\n",
      "Epoch 05430 | ep_reward 29.0 | T=29\n",
      "Epoch 05440 | ep_reward 12.0 | T=12\n",
      "Epoch 05450 | ep_reward 161.0 | T=161\n",
      "Epoch 05460 | ep_reward 93.0 | T=93\n",
      "Epoch 05470 | ep_reward 133.0 | T=133\n",
      "Epoch 05480 | ep_reward 86.0 | T=86\n",
      "Epoch 05490 | ep_reward 25.0 | T=25\n",
      "Epoch 05500 | ep_reward 189.0 | T=189\n",
      "Epoch 05510 | ep_reward 57.0 | T=57\n",
      "Epoch 05520 | ep_reward 46.0 | T=46\n",
      "Epoch 05530 | ep_reward 70.0 | T=70\n",
      "Epoch 05540 | ep_reward 60.0 | T=60\n",
      "Epoch 05550 | ep_reward 84.0 | T=84\n",
      "Epoch 05560 | ep_reward 92.0 | T=92\n",
      "Epoch 05570 | ep_reward 36.0 | T=36\n",
      "Epoch 05580 | ep_reward 48.0 | T=48\n",
      "Epoch 05590 | ep_reward 17.0 | T=17\n",
      "Epoch 05600 | ep_reward 117.0 | T=117\n",
      "Epoch 05610 | ep_reward 123.0 | T=123\n",
      "Epoch 05620 | ep_reward 174.0 | T=174\n",
      "Epoch 05630 | ep_reward 145.0 | T=145\n",
      "Epoch 05640 | ep_reward 161.0 | T=161\n",
      "Epoch 05650 | ep_reward 116.0 | T=116\n",
      "Epoch 05660 | ep_reward 233.0 | T=233\n",
      "Epoch 05670 | ep_reward 97.0 | T=97\n",
      "Epoch 05680 | ep_reward 17.0 | T=17\n",
      "Epoch 05690 | ep_reward 158.0 | T=158\n",
      "Epoch 05700 | ep_reward 150.0 | T=150\n",
      "Epoch 05710 | ep_reward 116.0 | T=116\n",
      "Epoch 05720 | ep_reward 79.0 | T=79\n",
      "Epoch 05730 | ep_reward 80.0 | T=80\n",
      "Epoch 05740 | ep_reward 77.0 | T=77\n",
      "Epoch 05750 | ep_reward 228.0 | T=228\n",
      "Epoch 05760 | ep_reward 20.0 | T=20\n",
      "Epoch 05770 | ep_reward 51.0 | T=51\n",
      "Epoch 05780 | ep_reward 69.0 | T=69\n",
      "Epoch 05790 | ep_reward 310.0 | T=310\n",
      "Epoch 05800 | ep_reward 185.0 | T=185\n",
      "Epoch 05810 | ep_reward 117.0 | T=117\n",
      "Epoch 05820 | ep_reward 112.0 | T=112\n",
      "Epoch 05830 | ep_reward 129.0 | T=129\n",
      "Epoch 05840 | ep_reward 132.0 | T=132\n",
      "Epoch 05850 | ep_reward 45.0 | T=45\n",
      "Epoch 05860 | ep_reward 158.0 | T=158\n",
      "Epoch 05870 | ep_reward 93.0 | T=93\n",
      "Epoch 05880 | ep_reward 15.0 | T=15\n",
      "Epoch 05890 | ep_reward 140.0 | T=140\n",
      "Epoch 05900 | ep_reward 11.0 | T=11\n",
      "Epoch 05910 | ep_reward 137.0 | T=137\n",
      "Epoch 05920 | ep_reward 188.0 | T=188\n",
      "Epoch 05930 | ep_reward 75.0 | T=75\n",
      "Epoch 05940 | ep_reward 66.0 | T=66\n",
      "Epoch 05950 | ep_reward 104.0 | T=104\n",
      "Epoch 05960 | ep_reward 135.0 | T=135\n",
      "Epoch 05970 | ep_reward 198.0 | T=198\n",
      "Epoch 05980 | ep_reward 51.0 | T=51\n",
      "Epoch 05990 | ep_reward 18.0 | T=18\n",
      "Epoch 06000 | ep_reward 236.0 | T=236\n",
      "Epoch 06010 | ep_reward 207.0 | T=207\n",
      "Epoch 06020 | ep_reward 269.0 | T=269\n",
      "Epoch 06030 | ep_reward 25.0 | T=25\n",
      "Epoch 06040 | ep_reward 351.0 | T=351\n",
      "Epoch 06050 | ep_reward 141.0 | T=141\n",
      "Epoch 06060 | ep_reward 248.0 | T=248\n",
      "Epoch 06070 | ep_reward 216.0 | T=216\n",
      "Epoch 06080 | ep_reward 129.0 | T=129\n",
      "Epoch 06090 | ep_reward 98.0 | T=98\n",
      "Epoch 06100 | ep_reward 79.0 | T=79\n",
      "Epoch 06110 | ep_reward 42.0 | T=42\n",
      "Epoch 06120 | ep_reward 95.0 | T=95\n",
      "Epoch 06130 | ep_reward 25.0 | T=25\n",
      "Epoch 06140 | ep_reward 11.0 | T=11\n",
      "Epoch 06150 | ep_reward 205.0 | T=205\n",
      "Epoch 06160 | ep_reward 31.0 | T=31\n",
      "Epoch 06170 | ep_reward 154.0 | T=154\n",
      "Epoch 06180 | ep_reward 32.0 | T=32\n",
      "Epoch 06190 | ep_reward 174.0 | T=174\n",
      "Epoch 06200 | ep_reward 218.0 | T=218\n",
      "Epoch 06210 | ep_reward 129.0 | T=129\n",
      "Epoch 06220 | ep_reward 159.0 | T=159\n",
      "Epoch 06230 | ep_reward 40.0 | T=40\n",
      "Epoch 06240 | ep_reward 73.0 | T=73\n",
      "Epoch 06250 | ep_reward 284.0 | T=284\n",
      "Epoch 06260 | ep_reward 67.0 | T=67\n",
      "Epoch 06270 | ep_reward 74.0 | T=74\n",
      "Epoch 06280 | ep_reward 186.0 | T=186\n",
      "Epoch 06290 | ep_reward 106.0 | T=106\n",
      "Epoch 06300 | ep_reward 411.0 | T=411\n",
      "Epoch 06310 | ep_reward 45.0 | T=45\n",
      "Epoch 06320 | ep_reward 154.0 | T=154\n",
      "Epoch 06330 | ep_reward 113.0 | T=113\n",
      "Epoch 06340 | ep_reward 23.0 | T=23\n",
      "Epoch 06350 | ep_reward 161.0 | T=161\n",
      "Epoch 06360 | ep_reward 237.0 | T=237\n",
      "Epoch 06370 | ep_reward 160.0 | T=160\n",
      "Epoch 06380 | ep_reward 171.0 | T=171\n",
      "Epoch 06390 | ep_reward 214.0 | T=214\n",
      "Epoch 06400 | ep_reward 167.0 | T=167\n",
      "Epoch 06410 | ep_reward 93.0 | T=93\n",
      "Epoch 06420 | ep_reward 59.0 | T=59\n",
      "Epoch 06430 | ep_reward 101.0 | T=101\n",
      "Epoch 06440 | ep_reward 24.0 | T=24\n",
      "Epoch 06450 | ep_reward 44.0 | T=44\n",
      "Epoch 06460 | ep_reward 97.0 | T=97\n",
      "Epoch 06470 | ep_reward 162.0 | T=162\n",
      "Epoch 06480 | ep_reward 185.0 | T=185\n",
      "Epoch 06490 | ep_reward 143.0 | T=143\n",
      "Epoch 06500 | ep_reward 100.0 | T=100\n",
      "Epoch 06510 | ep_reward 38.0 | T=38\n",
      "Epoch 06520 | ep_reward 13.0 | T=13\n",
      "Epoch 06530 | ep_reward 108.0 | T=108\n",
      "Epoch 06540 | ep_reward 157.0 | T=157\n",
      "Epoch 06550 | ep_reward 41.0 | T=41\n",
      "Epoch 06560 | ep_reward 129.0 | T=129\n",
      "Epoch 06570 | ep_reward 162.0 | T=162\n",
      "Epoch 06580 | ep_reward 48.0 | T=48\n",
      "Epoch 06590 | ep_reward 12.0 | T=12\n",
      "Epoch 06600 | ep_reward 50.0 | T=50\n",
      "Epoch 06610 | ep_reward 229.0 | T=229\n",
      "Epoch 06620 | ep_reward 41.0 | T=41\n",
      "Epoch 06630 | ep_reward 237.0 | T=237\n",
      "Epoch 06640 | ep_reward 85.0 | T=85\n",
      "Epoch 06650 | ep_reward 168.0 | T=168\n",
      "Epoch 06660 | ep_reward 47.0 | T=47\n",
      "Epoch 06670 | ep_reward 90.0 | T=90\n",
      "Epoch 06680 | ep_reward 100.0 | T=100\n",
      "Epoch 06690 | ep_reward 69.0 | T=69\n",
      "Epoch 06700 | ep_reward 29.0 | T=29\n",
      "Epoch 06710 | ep_reward 219.0 | T=219\n",
      "Epoch 06720 | ep_reward 116.0 | T=116\n",
      "Epoch 06730 | ep_reward 68.0 | T=68\n",
      "Epoch 06740 | ep_reward 176.0 | T=176\n",
      "Epoch 06750 | ep_reward 132.0 | T=132\n",
      "Epoch 06760 | ep_reward 216.0 | T=216\n",
      "Epoch 06770 | ep_reward 79.0 | T=79\n",
      "Epoch 06780 | ep_reward 216.0 | T=216\n",
      "Epoch 06790 | ep_reward 194.0 | T=194\n",
      "Epoch 06800 | ep_reward 46.0 | T=46\n",
      "Epoch 06810 | ep_reward 500.0 | T=500\n",
      "Epoch 06820 | ep_reward 56.0 | T=56\n",
      "Epoch 06830 | ep_reward 112.0 | T=112\n",
      "Epoch 06840 | ep_reward 99.0 | T=99\n",
      "Epoch 06850 | ep_reward 169.0 | T=169\n",
      "Epoch 06860 | ep_reward 112.0 | T=112\n",
      "Epoch 06870 | ep_reward 187.0 | T=187\n",
      "Epoch 06880 | ep_reward 72.0 | T=72\n",
      "Epoch 06890 | ep_reward 65.0 | T=65\n",
      "Epoch 06900 | ep_reward 159.0 | T=159\n",
      "Epoch 06910 | ep_reward 188.0 | T=188\n",
      "Epoch 06920 | ep_reward 86.0 | T=86\n",
      "Epoch 06930 | ep_reward 62.0 | T=62\n",
      "Epoch 06940 | ep_reward 159.0 | T=159\n",
      "Epoch 06950 | ep_reward 143.0 | T=143\n",
      "Epoch 06960 | ep_reward 220.0 | T=220\n",
      "Epoch 06970 | ep_reward 30.0 | T=30\n",
      "Epoch 06980 | ep_reward 330.0 | T=330\n",
      "Epoch 06990 | ep_reward 32.0 | T=32\n",
      "Epoch 07000 | ep_reward 111.0 | T=111\n",
      "Epoch 07010 | ep_reward 341.0 | T=341\n",
      "Epoch 07020 | ep_reward 104.0 | T=104\n",
      "Epoch 07030 | ep_reward 16.0 | T=16\n",
      "Epoch 07040 | ep_reward 95.0 | T=95\n",
      "Epoch 07050 | ep_reward 177.0 | T=177\n",
      "Epoch 07060 | ep_reward 43.0 | T=43\n",
      "Epoch 07070 | ep_reward 57.0 | T=57\n",
      "Epoch 07080 | ep_reward 128.0 | T=128\n",
      "Epoch 07090 | ep_reward 111.0 | T=111\n",
      "Epoch 07100 | ep_reward 176.0 | T=176\n",
      "Epoch 07110 | ep_reward 432.0 | T=432\n",
      "Epoch 07120 | ep_reward 16.0 | T=16\n",
      "Epoch 07130 | ep_reward 127.0 | T=127\n",
      "Epoch 07140 | ep_reward 159.0 | T=159\n",
      "Epoch 07150 | ep_reward 403.0 | T=403\n",
      "Epoch 07160 | ep_reward 252.0 | T=252\n",
      "Epoch 07170 | ep_reward 296.0 | T=296\n",
      "Epoch 07180 | ep_reward 37.0 | T=37\n",
      "Epoch 07190 | ep_reward 144.0 | T=144\n",
      "Epoch 07200 | ep_reward 60.0 | T=60\n",
      "Epoch 07210 | ep_reward 87.0 | T=87\n",
      "Epoch 07220 | ep_reward 170.0 | T=170\n",
      "Epoch 07230 | ep_reward 53.0 | T=53\n",
      "Epoch 07240 | ep_reward 142.0 | T=142\n",
      "Epoch 07250 | ep_reward 18.0 | T=18\n",
      "Epoch 07260 | ep_reward 197.0 | T=197\n",
      "Epoch 07270 | ep_reward 61.0 | T=61\n",
      "Epoch 07280 | ep_reward 116.0 | T=116\n",
      "Epoch 07290 | ep_reward 89.0 | T=89\n",
      "Epoch 07300 | ep_reward 324.0 | T=324\n",
      "Epoch 07310 | ep_reward 122.0 | T=122\n",
      "Epoch 07320 | ep_reward 268.0 | T=268\n",
      "Epoch 07330 | ep_reward 230.0 | T=230\n",
      "Epoch 07340 | ep_reward 38.0 | T=38\n",
      "Epoch 07350 | ep_reward 226.0 | T=226\n",
      "Epoch 07360 | ep_reward 211.0 | T=211\n",
      "Epoch 07370 | ep_reward 357.0 | T=357\n",
      "Epoch 07380 | ep_reward 74.0 | T=74\n",
      "Epoch 07390 | ep_reward 167.0 | T=167\n",
      "Epoch 07400 | ep_reward 109.0 | T=109\n",
      "Epoch 07410 | ep_reward 335.0 | T=335\n",
      "Epoch 07420 | ep_reward 149.0 | T=149\n",
      "Epoch 07430 | ep_reward 154.0 | T=154\n",
      "Epoch 07440 | ep_reward 200.0 | T=200\n",
      "Epoch 07450 | ep_reward 224.0 | T=224\n",
      "Epoch 07460 | ep_reward 327.0 | T=327\n",
      "Epoch 07470 | ep_reward 129.0 | T=129\n",
      "Epoch 07480 | ep_reward 37.0 | T=37\n",
      "Epoch 07490 | ep_reward 291.0 | T=291\n",
      "Epoch 07500 | ep_reward 244.0 | T=244\n",
      "Epoch 07510 | ep_reward 265.0 | T=265\n",
      "Epoch 07520 | ep_reward 85.0 | T=85\n",
      "Epoch 07530 | ep_reward 17.0 | T=17\n",
      "Epoch 07540 | ep_reward 145.0 | T=145\n",
      "Epoch 07550 | ep_reward 17.0 | T=17\n",
      "Epoch 07560 | ep_reward 160.0 | T=160\n",
      "Epoch 07570 | ep_reward 247.0 | T=247\n",
      "Epoch 07580 | ep_reward 222.0 | T=222\n",
      "Epoch 07590 | ep_reward 33.0 | T=33\n",
      "Epoch 07600 | ep_reward 171.0 | T=171\n",
      "Epoch 07610 | ep_reward 167.0 | T=167\n",
      "Epoch 07620 | ep_reward 181.0 | T=181\n",
      "Epoch 07630 | ep_reward 26.0 | T=26\n",
      "Epoch 07640 | ep_reward 138.0 | T=138\n",
      "Epoch 07650 | ep_reward 191.0 | T=191\n",
      "Epoch 07660 | ep_reward 118.0 | T=118\n",
      "Epoch 07670 | ep_reward 207.0 | T=207\n",
      "Epoch 07680 | ep_reward 128.0 | T=128\n",
      "Epoch 07690 | ep_reward 55.0 | T=55\n",
      "Epoch 07700 | ep_reward 327.0 | T=327\n",
      "Epoch 07710 | ep_reward 16.0 | T=16\n",
      "Epoch 07720 | ep_reward 228.0 | T=228\n",
      "Epoch 07730 | ep_reward 282.0 | T=282\n",
      "Epoch 07740 | ep_reward 239.0 | T=239\n",
      "Epoch 07750 | ep_reward 310.0 | T=310\n",
      "Epoch 07760 | ep_reward 215.0 | T=215\n",
      "Epoch 07770 | ep_reward 31.0 | T=31\n",
      "Epoch 07780 | ep_reward 28.0 | T=28\n",
      "Epoch 07790 | ep_reward 88.0 | T=88\n",
      "Epoch 07800 | ep_reward 126.0 | T=126\n",
      "Epoch 07810 | ep_reward 258.0 | T=258\n",
      "Epoch 07820 | ep_reward 253.0 | T=253\n",
      "Epoch 07830 | ep_reward 180.0 | T=180\n",
      "Epoch 07840 | ep_reward 97.0 | T=97\n",
      "Epoch 07850 | ep_reward 404.0 | T=404\n",
      "Epoch 07860 | ep_reward 66.0 | T=66\n",
      "Epoch 07870 | ep_reward 196.0 | T=196\n",
      "Epoch 07880 | ep_reward 226.0 | T=226\n",
      "Epoch 07890 | ep_reward 179.0 | T=179\n",
      "Epoch 07900 | ep_reward 217.0 | T=217\n",
      "Epoch 07910 | ep_reward 269.0 | T=269\n",
      "Epoch 07920 | ep_reward 61.0 | T=61\n",
      "Epoch 07930 | ep_reward 215.0 | T=215\n",
      "Epoch 07940 | ep_reward 140.0 | T=140\n",
      "Epoch 07950 | ep_reward 215.0 | T=215\n",
      "Epoch 07960 | ep_reward 58.0 | T=58\n",
      "Epoch 07970 | ep_reward 56.0 | T=56\n",
      "Epoch 07980 | ep_reward 387.0 | T=387\n",
      "Epoch 07990 | ep_reward 204.0 | T=204\n",
      "Epoch 08000 | ep_reward 227.0 | T=227\n",
      "Epoch 08010 | ep_reward 166.0 | T=166\n",
      "Epoch 08020 | ep_reward 246.0 | T=246\n",
      "Epoch 08030 | ep_reward 299.0 | T=299\n",
      "Epoch 08040 | ep_reward 257.0 | T=257\n",
      "Epoch 08050 | ep_reward 317.0 | T=317\n",
      "Epoch 08060 | ep_reward 186.0 | T=186\n",
      "Epoch 08070 | ep_reward 500.0 | T=500\n",
      "Epoch 08080 | ep_reward 134.0 | T=134\n",
      "Epoch 08090 | ep_reward 10.0 | T=10\n",
      "Epoch 08100 | ep_reward 55.0 | T=55\n",
      "Epoch 08110 | ep_reward 12.0 | T=12\n",
      "Epoch 08120 | ep_reward 201.0 | T=201\n",
      "Epoch 08130 | ep_reward 114.0 | T=114\n",
      "Epoch 08140 | ep_reward 42.0 | T=42\n",
      "Epoch 08150 | ep_reward 267.0 | T=267\n",
      "Epoch 08160 | ep_reward 281.0 | T=281\n",
      "Epoch 08170 | ep_reward 388.0 | T=388\n",
      "Epoch 08180 | ep_reward 226.0 | T=226\n",
      "Epoch 08190 | ep_reward 168.0 | T=168\n",
      "Epoch 08200 | ep_reward 148.0 | T=148\n",
      "Epoch 08210 | ep_reward 154.0 | T=154\n",
      "Epoch 08220 | ep_reward 283.0 | T=283\n",
      "Epoch 08230 | ep_reward 240.0 | T=240\n",
      "Epoch 08240 | ep_reward 62.0 | T=62\n",
      "Epoch 08250 | ep_reward 181.0 | T=181\n",
      "Epoch 08260 | ep_reward 124.0 | T=124\n",
      "Epoch 08270 | ep_reward 215.0 | T=215\n",
      "Epoch 08280 | ep_reward 244.0 | T=244\n",
      "Epoch 08290 | ep_reward 220.0 | T=220\n",
      "Epoch 08300 | ep_reward 120.0 | T=120\n",
      "Epoch 08310 | ep_reward 476.0 | T=476\n",
      "Epoch 08320 | ep_reward 178.0 | T=178\n",
      "Epoch 08330 | ep_reward 488.0 | T=488\n",
      "Epoch 08340 | ep_reward 384.0 | T=384\n",
      "Epoch 08350 | ep_reward 330.0 | T=330\n",
      "Epoch 08360 | ep_reward 40.0 | T=40\n",
      "Epoch 08370 | ep_reward 233.0 | T=233\n",
      "Epoch 08380 | ep_reward 46.0 | T=46\n",
      "Epoch 08390 | ep_reward 72.0 | T=72\n",
      "Epoch 08400 | ep_reward 191.0 | T=191\n",
      "Epoch 08410 | ep_reward 77.0 | T=77\n",
      "Epoch 08420 | ep_reward 465.0 | T=465\n",
      "Epoch 08430 | ep_reward 145.0 | T=145\n",
      "Epoch 08440 | ep_reward 142.0 | T=142\n",
      "Epoch 08450 | ep_reward 225.0 | T=225\n",
      "Epoch 08460 | ep_reward 133.0 | T=133\n",
      "Epoch 08470 | ep_reward 500.0 | T=500\n",
      "Epoch 08480 | ep_reward 256.0 | T=256\n",
      "Epoch 08490 | ep_reward 240.0 | T=240\n",
      "Epoch 08500 | ep_reward 216.0 | T=216\n",
      "Epoch 08510 | ep_reward 120.0 | T=120\n",
      "Epoch 08520 | ep_reward 164.0 | T=164\n",
      "Epoch 08530 | ep_reward 256.0 | T=256\n",
      "Epoch 08540 | ep_reward 151.0 | T=151\n",
      "Epoch 08550 | ep_reward 409.0 | T=409\n",
      "Epoch 08560 | ep_reward 83.0 | T=83\n",
      "Epoch 08570 | ep_reward 153.0 | T=153\n",
      "Epoch 08580 | ep_reward 225.0 | T=225\n",
      "Epoch 08590 | ep_reward 284.0 | T=284\n",
      "Epoch 08600 | ep_reward 380.0 | T=380\n",
      "Epoch 08610 | ep_reward 155.0 | T=155\n",
      "Epoch 08620 | ep_reward 44.0 | T=44\n",
      "Epoch 08630 | ep_reward 415.0 | T=415\n",
      "Epoch 08640 | ep_reward 165.0 | T=165\n",
      "Epoch 08650 | ep_reward 427.0 | T=427\n",
      "Epoch 08660 | ep_reward 239.0 | T=239\n",
      "Epoch 08670 | ep_reward 316.0 | T=316\n",
      "Epoch 08680 | ep_reward 137.0 | T=137\n",
      "Epoch 08690 | ep_reward 14.0 | T=14\n",
      "Epoch 08700 | ep_reward 107.0 | T=107\n",
      "Epoch 08710 | ep_reward 184.0 | T=184\n",
      "Epoch 08720 | ep_reward 247.0 | T=247\n",
      "Epoch 08730 | ep_reward 250.0 | T=250\n",
      "Epoch 08740 | ep_reward 220.0 | T=220\n",
      "Epoch 08750 | ep_reward 119.0 | T=119\n",
      "Epoch 08760 | ep_reward 217.0 | T=217\n",
      "Epoch 08770 | ep_reward 265.0 | T=265\n",
      "Epoch 08780 | ep_reward 175.0 | T=175\n",
      "Epoch 08790 | ep_reward 179.0 | T=179\n",
      "Epoch 08800 | ep_reward 204.0 | T=204\n",
      "Epoch 08810 | ep_reward 253.0 | T=253\n",
      "Epoch 08820 | ep_reward 26.0 | T=26\n",
      "Epoch 08830 | ep_reward 146.0 | T=146\n",
      "Epoch 08840 | ep_reward 166.0 | T=166\n",
      "Epoch 08850 | ep_reward 230.0 | T=230\n",
      "Epoch 08860 | ep_reward 194.0 | T=194\n",
      "Epoch 08870 | ep_reward 363.0 | T=363\n",
      "Epoch 08880 | ep_reward 179.0 | T=179\n",
      "Epoch 08890 | ep_reward 210.0 | T=210\n",
      "Epoch 08900 | ep_reward 293.0 | T=293\n",
      "Epoch 08910 | ep_reward 178.0 | T=178\n",
      "Epoch 08920 | ep_reward 75.0 | T=75\n",
      "Epoch 08930 | ep_reward 17.0 | T=17\n",
      "Epoch 08940 | ep_reward 231.0 | T=231\n",
      "Epoch 08950 | ep_reward 28.0 | T=28\n",
      "Epoch 08960 | ep_reward 299.0 | T=299\n",
      "Epoch 08970 | ep_reward 500.0 | T=500\n",
      "Epoch 08980 | ep_reward 205.0 | T=205\n",
      "Epoch 08990 | ep_reward 147.0 | T=147\n",
      "Epoch 09000 | ep_reward 250.0 | T=250\n",
      "Epoch 09010 | ep_reward 205.0 | T=205\n",
      "Epoch 09020 | ep_reward 172.0 | T=172\n",
      "Epoch 09030 | ep_reward 161.0 | T=161\n",
      "Epoch 09040 | ep_reward 233.0 | T=233\n",
      "Epoch 09050 | ep_reward 65.0 | T=65\n",
      "Epoch 09060 | ep_reward 204.0 | T=204\n",
      "Epoch 09070 | ep_reward 263.0 | T=263\n",
      "Epoch 09080 | ep_reward 169.0 | T=169\n",
      "Epoch 09090 | ep_reward 144.0 | T=144\n",
      "Epoch 09100 | ep_reward 235.0 | T=235\n",
      "Epoch 09110 | ep_reward 154.0 | T=154\n",
      "Epoch 09120 | ep_reward 296.0 | T=296\n",
      "Epoch 09130 | ep_reward 97.0 | T=97\n",
      "Epoch 09140 | ep_reward 14.0 | T=14\n",
      "Epoch 09150 | ep_reward 10.0 | T=10\n",
      "Epoch 09160 | ep_reward 181.0 | T=181\n",
      "Epoch 09170 | ep_reward 141.0 | T=141\n",
      "Epoch 09180 | ep_reward 120.0 | T=120\n",
      "Epoch 09190 | ep_reward 147.0 | T=147\n",
      "Epoch 09200 | ep_reward 306.0 | T=306\n",
      "Epoch 09210 | ep_reward 113.0 | T=113\n",
      "Epoch 09220 | ep_reward 11.0 | T=11\n",
      "Epoch 09230 | ep_reward 195.0 | T=195\n",
      "Epoch 09240 | ep_reward 221.0 | T=221\n",
      "Epoch 09250 | ep_reward 500.0 | T=500\n",
      "Epoch 09260 | ep_reward 201.0 | T=201\n",
      "Epoch 09270 | ep_reward 205.0 | T=205\n",
      "Epoch 09280 | ep_reward 136.0 | T=136\n",
      "Epoch 09290 | ep_reward 147.0 | T=147\n",
      "Epoch 09300 | ep_reward 196.0 | T=196\n",
      "Epoch 09310 | ep_reward 27.0 | T=27\n",
      "Epoch 09320 | ep_reward 367.0 | T=367\n",
      "Epoch 09330 | ep_reward 12.0 | T=12\n",
      "Epoch 09340 | ep_reward 173.0 | T=173\n",
      "Epoch 09350 | ep_reward 500.0 | T=500\n",
      "Epoch 09360 | ep_reward 109.0 | T=109\n",
      "Epoch 09370 | ep_reward 287.0 | T=287\n",
      "Epoch 09380 | ep_reward 143.0 | T=143\n",
      "Epoch 09390 | ep_reward 111.0 | T=111\n",
      "Epoch 09400 | ep_reward 154.0 | T=154\n",
      "Epoch 09410 | ep_reward 358.0 | T=358\n",
      "Epoch 09420 | ep_reward 234.0 | T=234\n",
      "Epoch 09430 | ep_reward 189.0 | T=189\n",
      "Epoch 09440 | ep_reward 266.0 | T=266\n",
      "Epoch 09450 | ep_reward 133.0 | T=133\n",
      "Epoch 09460 | ep_reward 259.0 | T=259\n",
      "Epoch 09470 | ep_reward 287.0 | T=287\n",
      "Epoch 09480 | ep_reward 238.0 | T=238\n",
      "Epoch 09490 | ep_reward 137.0 | T=137\n",
      "Epoch 09500 | ep_reward 173.0 | T=173\n",
      "Epoch 09510 | ep_reward 64.0 | T=64\n",
      "Epoch 09520 | ep_reward 195.0 | T=195\n",
      "Epoch 09530 | ep_reward 465.0 | T=465\n",
      "Epoch 09540 | ep_reward 71.0 | T=71\n",
      "Epoch 09550 | ep_reward 500.0 | T=500\n",
      "Epoch 09560 | ep_reward 434.0 | T=434\n",
      "Epoch 09570 | ep_reward 86.0 | T=86\n",
      "Epoch 09580 | ep_reward 259.0 | T=259\n",
      "Epoch 09590 | ep_reward 179.0 | T=179\n",
      "Epoch 09600 | ep_reward 500.0 | T=500\n",
      "Epoch 09610 | ep_reward 116.0 | T=116\n",
      "Epoch 09620 | ep_reward 198.0 | T=198\n",
      "Epoch 09630 | ep_reward 137.0 | T=137\n",
      "Epoch 09640 | ep_reward 167.0 | T=167\n",
      "Epoch 09650 | ep_reward 223.0 | T=223\n",
      "Epoch 09660 | ep_reward 283.0 | T=283\n",
      "Epoch 09670 | ep_reward 185.0 | T=185\n",
      "Epoch 09680 | ep_reward 179.0 | T=179\n",
      "Epoch 09690 | ep_reward 304.0 | T=304\n",
      "Epoch 09700 | ep_reward 22.0 | T=22\n",
      "Epoch 09710 | ep_reward 471.0 | T=471\n",
      "Epoch 09720 | ep_reward 185.0 | T=185\n",
      "Epoch 09730 | ep_reward 232.0 | T=232\n",
      "Epoch 09740 | ep_reward 167.0 | T=167\n",
      "Epoch 09750 | ep_reward 90.0 | T=90\n",
      "Epoch 09760 | ep_reward 281.0 | T=281\n",
      "Epoch 09770 | ep_reward 131.0 | T=131\n",
      "Epoch 09780 | ep_reward 15.0 | T=15\n",
      "Epoch 09790 | ep_reward 365.0 | T=365\n",
      "Epoch 09800 | ep_reward 154.0 | T=154\n",
      "Epoch 09810 | ep_reward 330.0 | T=330\n",
      "Epoch 09820 | ep_reward 159.0 | T=159\n",
      "Epoch 09830 | ep_reward 167.0 | T=167\n",
      "Epoch 09840 | ep_reward 160.0 | T=160\n",
      "Epoch 09850 | ep_reward 368.0 | T=368\n",
      "Epoch 09860 | ep_reward 118.0 | T=118\n",
      "Epoch 09870 | ep_reward 143.0 | T=143\n",
      "Epoch 09880 | ep_reward 352.0 | T=352\n",
      "Epoch 09890 | ep_reward 500.0 | T=500\n",
      "Epoch 09900 | ep_reward 263.0 | T=263\n",
      "Epoch 09910 | ep_reward 169.0 | T=169\n",
      "Epoch 09920 | ep_reward 204.0 | T=204\n",
      "Epoch 09930 | ep_reward 354.0 | T=354\n",
      "Epoch 09940 | ep_reward 27.0 | T=27\n",
      "Epoch 09950 | ep_reward 214.0 | T=214\n",
      "Epoch 09960 | ep_reward 133.0 | T=133\n",
      "Epoch 09970 | ep_reward 53.0 | T=53\n",
      "Epoch 09980 | ep_reward 14.0 | T=14\n",
      "Epoch 09990 | ep_reward 226.0 | T=226\n",
      "Epoch 10000 | ep_reward 72.0 | T=72\n",
      "Epoch 10010 | ep_reward 63.0 | T=63\n",
      "Epoch 10020 | ep_reward 375.0 | T=375\n",
      "Epoch 10030 | ep_reward 53.0 | T=53\n",
      "Epoch 10040 | ep_reward 448.0 | T=448\n",
      "Epoch 10050 | ep_reward 12.0 | T=12\n",
      "Epoch 10060 | ep_reward 193.0 | T=193\n",
      "Epoch 10070 | ep_reward 322.0 | T=322\n",
      "Epoch 10080 | ep_reward 63.0 | T=63\n",
      "Epoch 10090 | ep_reward 43.0 | T=43\n",
      "Epoch 10100 | ep_reward 196.0 | T=196\n",
      "Epoch 10110 | ep_reward 258.0 | T=258\n",
      "Epoch 10120 | ep_reward 166.0 | T=166\n",
      "Epoch 10130 | ep_reward 122.0 | T=122\n",
      "Epoch 10140 | ep_reward 238.0 | T=238\n",
      "Epoch 10150 | ep_reward 192.0 | T=192\n",
      "Epoch 10160 | ep_reward 190.0 | T=190\n",
      "Epoch 10170 | ep_reward 461.0 | T=461\n",
      "Epoch 10180 | ep_reward 500.0 | T=500\n",
      "Epoch 10190 | ep_reward 274.0 | T=274\n",
      "Epoch 10200 | ep_reward 14.0 | T=14\n",
      "Epoch 10210 | ep_reward 500.0 | T=500\n",
      "Epoch 10220 | ep_reward 424.0 | T=424\n",
      "Epoch 10230 | ep_reward 341.0 | T=341\n",
      "Epoch 10240 | ep_reward 500.0 | T=500\n",
      "Epoch 10250 | ep_reward 112.0 | T=112\n",
      "Epoch 10260 | ep_reward 168.0 | T=168\n",
      "Epoch 10270 | ep_reward 500.0 | T=500\n",
      "Epoch 10280 | ep_reward 282.0 | T=282\n",
      "Epoch 10290 | ep_reward 500.0 | T=500\n",
      "Epoch 10300 | ep_reward 185.0 | T=185\n",
      "Epoch 10310 | ep_reward 157.0 | T=157\n",
      "Epoch 10320 | ep_reward 500.0 | T=500\n",
      "Epoch 10330 | ep_reward 500.0 | T=500\n",
      "Epoch 10340 | ep_reward 86.0 | T=86\n",
      "Epoch 10350 | ep_reward 147.0 | T=147\n",
      "Epoch 10360 | ep_reward 293.0 | T=293\n",
      "Epoch 10370 | ep_reward 500.0 | T=500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m states\u001b[38;5;241m.\u001b[39mappend(state\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[0;32m     90\u001b[0m state_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(state, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m action, (a_hx, a_cx) \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_hx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_cx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m actions\u001b[38;5;241m.\u001b[39mappend(action)\n\u001b[0;32m     94\u001b[0m next_obs, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "Cell \u001b[1;32mIn[2], line 35\u001b[0m, in \u001b[0;36mPolicyNetwork.select_action\u001b[1;34m(self, state, hidden)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mselect_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, hidden):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# state: (1, 1, 2)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 35\u001b[0m         prob, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (1,1,1)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         b \u001b[38;5;241m=\u001b[39m Bernoulli(prob)\n\u001b[0;32m     37\u001b[0m         action \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39msample()  \u001b[38;5;66;03m# 0/1\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m, in \u001b[0;36mPolicyNetwork.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# x: (B, T, 2)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[1;32m---> 27\u001b[0m     x, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))  \u001b[38;5;66;03m# (B, T, 1)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\82108\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\82108\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\82108\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1137\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)\n",
    "        self.lstm = nn.LSTM(64, 128, batch_first=True)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # x: (B, T, 2)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        x = self.relu(x)\n",
    "        x = self.sigmoid(self.fc2(x))  # (B, T, 1)\n",
    "        return x, hidden\n",
    "\n",
    "    def select_action(self, state, hidden):\n",
    "        # state: (1, 1, 2)\n",
    "        with torch.no_grad():\n",
    "            prob, hidden = self.forward(state, hidden)  # (1,1,1)\n",
    "            b = Bernoulli(prob)\n",
    "            action = b.sample()  # 0/1\n",
    "        return int(action.item()), hidden\n",
    "\n",
    "\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)\n",
    "        self.lstm = nn.LSTM(64, 256, batch_first=True)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)  # (B,T,1)\n",
    "        return x, hidden\n",
    "\n",
    "\n",
    "def obs_to_partial(obs):\n",
    "    # CartPole obs: [x, x_dot, theta, theta_dot]\n",
    "    # keep only x, theta\n",
    "    return np.array([obs[0], obs[2]], dtype=np.float32)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    policy = PolicyNetwork().to(device)\n",
    "    value = ValueNetwork().to(device)\n",
    "\n",
    "    optim = torch.optim.Adam(policy.parameters(), lr=1e-4)\n",
    "    value_optim = torch.optim.Adam(value.parameters(), lr=3e-4)\n",
    "\n",
    "    gamma = 0.99\n",
    "    writer = SummaryWriter(\"./lstm_logs\")\n",
    "\n",
    "    for epoch in count():\n",
    "        obs, info = env.reset(seed=None)\n",
    "        state = obs_to_partial(obs)\n",
    "        episode_reward = 0.0\n",
    "\n",
    "        # LSTM hidden init\n",
    "        a_hx = torch.zeros((1, 1, 128), device=device)\n",
    "        a_cx = torch.zeros((1, 1, 128), device=device)\n",
    "\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        states = []\n",
    "\n",
    "        for t in range(500):  # CartPole-v1 max is typically 500\n",
    "            states.append(state.copy())\n",
    "\n",
    "            state_t = torch.tensor(state, dtype=torch.float32, device=device).view(1, 1, 2)\n",
    "            action, (a_hx, a_cx) = policy.select_action(state_t, (a_hx, a_cx))\n",
    "            actions.append(action)\n",
    "\n",
    "            next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            next_state = obs_to_partial(next_obs)\n",
    "            episode_reward += float(reward)\n",
    "\n",
    "            rewards.append(float(reward))\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # returns\n",
    "        returns = np.zeros(len(rewards), dtype=np.float32)\n",
    "        R = 0.0\n",
    "        for i in reversed(range(len(rewards))):\n",
    "            R = gamma * R + rewards[i]\n",
    "            returns[i] = R\n",
    "\n",
    "        # normalize returns (stability)\n",
    "        mean, std = returns.mean(), returns.std()\n",
    "        std = std if std > 1e-8 else 1.0\n",
    "        returns = (returns - mean) / std\n",
    "\n",
    "        # tensors\n",
    "        states_tensor = torch.tensor(np.array(states), dtype=torch.float32, device=device).unsqueeze(0)  # (1,T,2)\n",
    "        actions_tensor = torch.tensor(np.array(actions), dtype=torch.float32, device=device).view(-1, 1)  # (T,1)\n",
    "        returns_tensor = torch.tensor(returns, dtype=torch.float32, device=device).view(-1, 1)  # (T,1)\n",
    "\n",
    "        # critic to get baseline\n",
    "        with torch.no_grad():\n",
    "            c_hx = torch.zeros((1, 1, 256), device=device)\n",
    "            c_cx = torch.zeros((1, 1, 256), device=device)\n",
    "            v, _ = value(states_tensor, (c_hx, c_cx))  # (1,T,1)\n",
    "            v = v.squeeze(0)  # (T,1)\n",
    "            advantage = returns_tensor - v  # (T,1)\n",
    "\n",
    "        # actor update (re-run policy on full sequence)\n",
    "        a_hx = torch.zeros((1, 1, 128), device=device)\n",
    "        a_cx = torch.zeros((1, 1, 128), device=device)\n",
    "        prob, _ = policy(states_tensor, (a_hx, a_cx))  # (1,T,1)\n",
    "        prob = prob.squeeze(0)  # (T,1)\n",
    "\n",
    "        b = Bernoulli(prob)\n",
    "        log_prob = b.log_prob(actions_tensor)  # (T,1)\n",
    "\n",
    "        actor_loss = -(log_prob * advantage.detach()).mean()\n",
    "\n",
    "        optim.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(policy.parameters(), 1.0)\n",
    "        optim.step()\n",
    "        writer.add_scalar(\"loss/actor\", actor_loss.item(), epoch)\n",
    "\n",
    "        # critic update\n",
    "        c_hx = torch.zeros((1, 1, 256), device=device)\n",
    "        c_cx = torch.zeros((1, 1, 256), device=device)\n",
    "        v, _ = value(states_tensor, (c_hx, c_cx))\n",
    "        v = v.squeeze(0)\n",
    "        value_loss = F.mse_loss(v, returns_tensor)\n",
    "\n",
    "        value_optim.zero_grad()\n",
    "        value_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(value.parameters(), 1.0)\n",
    "        value_optim.step()\n",
    "        writer.add_scalar(\"loss/value\", value_loss.item(), epoch)\n",
    "\n",
    "        writer.add_scalar(\"episode_reward\", episode_reward, epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch:05d} | ep_reward {episode_reward:.1f} | T={len(rewards)}\")\n",
    "            torch.save(policy.state_dict(), \"lstm-policy.pt\")\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80988084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Visualization (paper-ready)\n",
    "# =========================\n",
    "# This cell reads TensorBoard event files written by SummaryWriter(\"./lstm_logs\")\n",
    "# and produces publication-friendly learning curves:\n",
    "# - mean  std over seeds (if multiple runs exist)\n",
    "# - moving-average smoothing\n",
    "# - ablation comparison across multiple experiment folders\n",
    "#\n",
    "# Usage:\n",
    "# 1) Run training one or more times (ideally with different seeds & different log dirs).\n",
    "# 2) Set LOGROOTS below to point at your log folders.\n",
    "# 3) Run this cell.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "\n",
    "def _find_event_files(logdir: str):\n",
    "    \"\"\"Return a list of TensorBoard event files under logdir (recursive).\"\"\"\n",
    "    patterns = [\n",
    "        os.path.join(logdir, \"**\", \"events.out.tfevents.*\"),\n",
    "        os.path.join(logdir, \"events.out.tfevents.*\"),\n",
    "    ]\n",
    "    files = []\n",
    "    for p in patterns:\n",
    "        files.extend(glob.glob(p, recursive=True))\n",
    "    return sorted(list(set(files)))\n",
    "\n",
    "\n",
    "def _load_scalars_from_event(event_file: str, tags=None):\n",
    "    \"\"\"Load scalar time-series from one event file into a tidy DataFrame.\"\"\"\n",
    "    ea = EventAccumulator(event_file, size_guidance={\"scalars\": 0})\n",
    "    ea.Reload()\n",
    "\n",
    "    available = set(ea.Tags().get(\"scalars\", []))\n",
    "    if tags is None:\n",
    "        tags = sorted(list(available))\n",
    "    else:\n",
    "        tags = [t for t in tags if t in available]\n",
    "\n",
    "    rows = []\n",
    "    for tag in tags:\n",
    "        for ev in ea.Scalars(tag):\n",
    "            rows.append({\n",
    "                \"tag\": tag,\n",
    "                \"step\": int(ev.step),\n",
    "                \"value\": float(ev.value),\n",
    "            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_tb_runs(logroot: str, tags=None):\n",
    "    \"\"\"\n",
    "    Read all event files under logroot.\n",
    "    Each event file is treated as one 'run' (seed/trial).\n",
    "    Returns a tidy DataFrame with columns: [group, run, tag, step, value].\n",
    "    \"\"\"\n",
    "    event_files = _find_event_files(logroot)\n",
    "    if len(event_files) == 0:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No TensorBoard event files found under: {logroot}\\n\"\n",
    "            f\"Expected something like: {logroot}/events.out.tfevents.*\"\n",
    "        )\n",
    "\n",
    "    dfs = []\n",
    "    for i, ef in enumerate(event_files):\n",
    "        run_name = os.path.relpath(os.path.dirname(ef), logroot)\n",
    "        # if event file is directly under logroot, relpath becomes \".\"\n",
    "        if run_name == \".\":\n",
    "            run_name = f\"run{i:02d}\"\n",
    "        df = _load_scalars_from_event(ef, tags=tags)\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "        df[\"group\"] = os.path.basename(os.path.normpath(logroot))\n",
    "        df[\"run\"] = run_name\n",
    "        df[\"event_file\"] = os.path.basename(ef)\n",
    "        dfs.append(df)\n",
    "\n",
    "    if len(dfs) == 0:\n",
    "        raise RuntimeError(f\"Found event files under {logroot}, but no scalar tags matched.\")\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "def moving_average(x, window=20):\n",
    "    if window is None or window <= 1:\n",
    "        return x\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if len(x) < window:\n",
    "        return x\n",
    "    w = np.ones(window, dtype=float) / float(window)\n",
    "    return np.convolve(x, w, mode=\"valid\")\n",
    "\n",
    "\n",
    "def summarize_runs(df: pd.DataFrame, tag: str, window=20):\n",
    "    \"\"\"\n",
    "    Build per-step mean/std across runs for a given tag.\n",
    "    We first align by 'step' (outer join), then compute mean/std.\n",
    "    Optionally apply moving-average smoothing to each run before aggregation.\n",
    "    \"\"\"\n",
    "    d = df[df[\"tag\"] == tag].copy()\n",
    "    if d.empty:\n",
    "        return None\n",
    "\n",
    "    # Pivot to [step x run] matrix for one group at a time later.\n",
    "    return d\n",
    "\n",
    "\n",
    "def plot_tag_across_groups(df_all: pd.DataFrame, tag: str, window=20, xlabel=\"Epoch\", ylabel=None, title=None):\n",
    "    \"\"\"\n",
    "    Plot mean  std across runs for each group (experiment folder) for the given tag.\n",
    "    \"\"\"\n",
    "    if ylabel is None:\n",
    "        ylabel = tag\n",
    "\n",
    "    plt.figure(figsize=(7, 4.2))\n",
    "    any_plotted = False\n",
    "\n",
    "    for group, dg in df_all.groupby(\"group\"):\n",
    "        d = dg[dg[\"tag\"] == tag].copy()\n",
    "        if d.empty:\n",
    "            continue\n",
    "\n",
    "        # Per-run smoothing, then align on step\n",
    "        series = {}\n",
    "        for run, dr in d.groupby(\"run\"):\n",
    "            dr = dr.sort_values(\"step\")\n",
    "            y = dr[\"value\"].to_numpy()\n",
    "            x = dr[\"step\"].to_numpy()\n",
    "\n",
    "            if window and window > 1 and len(y) >= window:\n",
    "                y_s = moving_average(y, window=window)\n",
    "                x_s = x[window-1:]  # align with 'valid' conv\n",
    "            else:\n",
    "                y_s = y\n",
    "                x_s = x\n",
    "\n",
    "            series[run] = pd.Series(y_s, index=x_s)\n",
    "\n",
    "        mat = pd.concat(series, axis=1)  # index=step, columns=run\n",
    "        mean = mat.mean(axis=1, skipna=True)\n",
    "        std = mat.std(axis=1, skipna=True)\n",
    "\n",
    "        plt.plot(mean.index.to_numpy(), mean.to_numpy(), label=f\"{group} (n={mat.shape[1]})\")\n",
    "        plt.fill_between(mean.index.to_numpy(),\n",
    "                         (mean - std).to_numpy(),\n",
    "                         (mean + std).to_numpy(),\n",
    "                         alpha=0.2)\n",
    "        any_plotted = True\n",
    "\n",
    "    if not any_plotted:\n",
    "        print(f\"[warn] Tag not found in any group: {tag}\")\n",
    "        return\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Configure your log folders\n",
    "# -------------------------\n",
    "# Put each experiment (baseline / ablation variants) into a separate folder.\n",
    "# Example layout:\n",
    "#   ./logs_baseline/seed0/events.out.tfevents...\n",
    "#   ./logs_baseline/seed1/events.out.tfevents...\n",
    "#   ./logs_modelA/seed0/events.out.tfevents...\n",
    "#   ./logs_modelA/seed1/events.out.tfevents...\n",
    "#\n",
    "# If you only have one folder (the current code writes to ./lstm_logs),\n",
    "# just keep baseline only.\n",
    "\n",
    "LOGROOTS = {\n",
    "    \"baseline\": \"./lstm_logs\",\n",
    "    # \"modelA\": \"./logs_modelA\",\n",
    "    # \"modelB\": \"./logs_modelB\",\n",
    "    # \"modelC\": \"./logs_modelC\",\n",
    "}\n",
    "\n",
    "# Tags we care about (only those present will be loaded)\n",
    "TAGS = [\n",
    "    \"episode_reward\",\n",
    "    \"loss/policy\",\n",
    "    \"loss/value\",\n",
    "    \"loss/total\",\n",
    "    \"success\",\n",
    "    \"succ\",\n",
    "    \"episode_length\",\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Load & plot\n",
    "# -------------------------\n",
    "dfs = []\n",
    "for name, root in LOGROOTS.items():\n",
    "    if not os.path.exists(root):\n",
    "        print(f\"[skip] missing log dir: {root}\")\n",
    "        continue\n",
    "    d = load_tb_runs(root, tags=TAGS)\n",
    "    # Override group label with friendly name (instead of folder basename)\n",
    "    d[\"group\"] = name\n",
    "    dfs.append(d)\n",
    "\n",
    "if len(dfs) == 0:\n",
    "    raise RuntimeError(\"No logs loaded. Check LOGROOTS paths above.\")\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(\"Loaded groups:\", df_all[\"group\"].unique().tolist())\n",
    "print(\"Available tags:\", sorted(df_all[\"tag\"].unique().tolist()))\n",
    "\n",
    "# Paper-friendly smoothing window (tune as needed)\n",
    "SMOOTH = 20\n",
    "\n",
    "# 1) Learning curve (Reward)\n",
    "plot_tag_across_groups(\n",
    "    df_all, \"episode_reward\",\n",
    "    window=SMOOTH,\n",
    "    xlabel=\"Epoch\",\n",
    "    ylabel=\"Episode return\",\n",
    "    title=\"Learning curve (mean  std across seeds)\"\n",
    ")\n",
    "\n",
    "# 2) Success rate, if logged\n",
    "# (Your current training code does not log success. If you add writer.add_scalar('success', ...),\n",
    "# this plot will automatically appear.)\n",
    "for succ_tag in [\"success\", \"succ\"]:\n",
    "    if succ_tag in set(df_all[\"tag\"].unique()):\n",
    "        plot_tag_across_groups(\n",
    "            df_all, succ_tag,\n",
    "            window=SMOOTH,\n",
    "            xlabel=\"Epoch\",\n",
    "            ylabel=\"Success rate\",\n",
    "            title=\"Success rate (mean  std across seeds)\"\n",
    "        )\n",
    "\n",
    "# 3) Loss curves\n",
    "for t in [\"loss/policy\", \"loss/value\", \"loss/total\"]:\n",
    "    if t in set(df_all[\"tag\"].unique()):\n",
    "        plot_tag_across_groups(\n",
    "            df_all, t,\n",
    "            window=SMOOTH,\n",
    "            xlabel=\"Epoch\",\n",
    "            ylabel=t,\n",
    "            title=f\"{t} (mean  std across seeds)\"\n",
    "        )\n",
    "\n",
    "# -------------------------\n",
    "# Optional: Save figures\n",
    "# -------------------------\n",
    "# Uncomment to export figures as .png (good for paper drafts).\n",
    "# os.makedirs(\"figs\", exist_ok=True)\n",
    "# for tag, fname, ylabel in [\n",
    "#     (\"episode_reward\", \"learning_curve_reward.png\", \"Episode return\"),\n",
    "#     (\"loss/policy\", \"loss_policy.png\", \"loss/policy\"),\n",
    "#     (\"loss/value\", \"loss_value.png\", \"loss/value\"),\n",
    "# ]:\n",
    "#     if tag not in set(df_all[\"tag\"].unique()):\n",
    "#         continue\n",
    "#     plt.figure(figsize=(7,4.2))\n",
    "#     for group, dg in df_all.groupby(\"group\"):\n",
    "#         d = dg[dg[\"tag\"] == tag].copy()\n",
    "#         if d.empty:\n",
    "#             continue\n",
    "#         series = {}\n",
    "#         for run, dr in d.groupby(\"run\"):\n",
    "#             dr = dr.sort_values(\"step\")\n",
    "#             y = dr[\"value\"].to_numpy()\n",
    "#             x = dr[\"step\"].to_numpy()\n",
    "#             if SMOOTH and SMOOTH > 1 and len(y) >= SMOOTH:\n",
    "#                 y_s = moving_average(y, window=SMOOTH)\n",
    "#                 x_s = x[SMOOTH-1:]\n",
    "#             else:\n",
    "#                 y_s, x_s = y, x\n",
    "#             series[run] = pd.Series(y_s, index=x_s)\n",
    "#         mat = pd.concat(series, axis=1)\n",
    "#         mean = mat.mean(axis=1, skipna=True)\n",
    "#         std = mat.std(axis=1, skipna=True)\n",
    "#         plt.plot(mean.index.to_numpy(), mean.to_numpy(), label=f\"{group} (n={mat.shape[1]})\")\n",
    "#         plt.fill_between(mean.index.to_numpy(),\n",
    "#                          (mean-std).to_numpy(),\n",
    "#                          (mean+std).to_numpy(),\n",
    "#                          alpha=0.2)\n",
    "#     plt.xlabel(\"Epoch\"); plt.ylabel(ylabel); plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout()\n",
    "#     plt.savefig(os.path.join(\"figs\", fname), dpi=300)\n",
    "#     plt.close()\n",
    "# print(\"Saved figures to ./figs\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
